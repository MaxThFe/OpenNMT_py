Search.setIndex({"docnames": ["CONTRIBUTING", "FAQ", "changes", "examples/ggnn/GGNN", "examples/replicate_vicuna/ReplicateVicuna", "examples/summary/Summarization", "examples/wiki_103/LanguageModelGeneration", "examples/wmt17/Translation", "examples/wmt17/old_translation", "index", "legacy/FAQ", "legacy/im2text", "legacy/speech2text", "legacy/vid2text", "main", "onmt", "onmt.inputters", "onmt.modules", "onmt.translate.translation_server", "onmt.translation", "options/build_vocab", "options/server", "options/train", "options/translate", "quickstart", "ref"], "filenames": ["CONTRIBUTING.md", "FAQ.md", "changes.md", "examples/ggnn/GGNN.md", "examples/replicate_vicuna/ReplicateVicuna.md", "examples/summary/Summarization.md", "examples/wiki_103/LanguageModelGeneration.md", "examples/wmt17/Translation.md", "examples/wmt17/old_translation.md", "index.rst", "legacy/FAQ.md", "legacy/im2text.md", "legacy/speech2text.md", "legacy/vid2text.rst", "main.md", "onmt.rst", "onmt.inputters.rst", "onmt.modules.rst", "onmt.translate.translation_server.rst", "onmt.translation.rst", "options/build_vocab.rst", "options/server.rst", "options/train.rst", "options/translate.rst", "quickstart.md", "ref.rst"], "titles": ["Contributors", "How do I use my v2 models in v3 ?", "Versions", "Gated Graph Neural Networks", "Supervised Finetuning of llama 7B to replicate Vicuna", "Summarization CNN/DM", "Language Model Wiki-103", "Translation WMT17 en-de", "Translation", "Contents", "FAQ (Legacy version)", "Image to Text", "Speech to Text", "Video to Text", "Overview", "Framework", "Data Loaders", "Modules", "Server", "Translation", "Build Vocab", "Server", "Train", "Translate", "Quickstart", "References"], "terms": {"opennmt": [0, 2, 3, 4, 5, 9, 10, 11, 12, 13, 14, 15, 21], "py": [0, 2, 3, 5, 6, 9, 10, 11, 12, 13, 14, 15, 20, 21, 22, 23], "i": [0, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24, 25], "commun": [0, 1, 10], "develop": [0, 1, 2], "project": [0, 14, 17], "we": [0, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 18, 19, 22, 24], "love": 0, "contribut": 0, "befor": [0, 1, 3, 5, 8, 10, 15, 18, 19, 23, 24], "send": [0, 1, 10, 22], "pr": [0, 2], "pleas": [0, 1, 3, 5, 10, 14, 24], "do": [0, 4, 5, 8, 9, 13, 18, 19, 22, 23, 24], "thi": [0, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 22, 23, 24], "checklist": 0, "first": [0, 1, 3, 4, 10, 12, 13, 17, 19, 22], "run": [0, 1, 2, 3, 4, 5, 6, 8, 9, 10, 13, 15, 17, 18, 22, 23, 24], "onmt": [0, 1, 4, 6, 7, 15, 16, 17, 18, 19, 20, 22, 24], "test": [0, 1, 3, 4, 5, 6, 7, 8, 11, 13, 22, 23, 24], "pull_request_chk": 0, "sh": [0, 3, 6, 7, 8, 13], "fix": [0, 1, 5, 19, 22], "ani": [0, 1, 2, 3, 5, 15, 19, 20, 22, 23, 24], "error": [0, 20, 22, 23], "when": [0, 5, 8, 9, 10, 14, 16, 17, 19, 20, 22, 23], "ad": [0, 1, 3, 5, 15, 20, 22, 23], "new": [0, 1, 2, 4, 8, 13, 24], "function": [0, 1, 4, 15, 16, 17, 18, 19, 22], "also": [0, 1, 4, 5, 13, 15, 17, 22, 24], "add": [0, 8, 10, 13, 15, 16, 17, 22, 23, 24], "script": [0, 1, 4, 5, 7, 8, 10, 13, 20, 22, 23], "includ": [0, 1, 3, 4, 5, 17, 20, 22, 23], "check": [0, 2, 5, 7], "flake8": 0, "code": [0, 3, 5, 13, 20, 22, 23], "style": [0, 3, 9, 17, 22], "unittest": 0, "continu": [0, 1, 13], "integr": [0, 1, 3], "list": [0, 3, 10, 13, 15, 17, 18, 19, 20, 22, 23], "github": [0, 1, 3, 4, 5, 7, 12, 14, 17, 22], "workflow": [0, 14], "push": 0, "yml": 0, "modifi": [0, 1, 2, 4, 5, 10, 15, 19], "class": [0, 1, 2, 9, 15, 16, 17, 18], "constructor": [0, 17], "make": [0, 1, 2, 4, 5, 10, 13, 16, 20, 22, 23], "argument": [0, 1, 9, 13, 15], "same": [0, 1, 2, 4, 5, 6, 8, 10, 13, 15, 17, 18, 20, 22, 23], "name": [0, 1, 4, 7, 9, 13, 16, 19, 22], "its": [0, 1, 3, 4, 15, 17], "superclass": 0, "pytorch": [0, 1, 2, 3, 5, 12, 14, 17, 22, 23], "If": [0, 1, 2, 3, 5, 8, 10, 13, 14, 15, 17, 18, 19, 22, 23, 24], "your": [0, 1, 2, 4, 5, 10], "chang": [0, 1, 4, 5, 9, 13, 15, 22], "base": [0, 1, 2, 3, 5, 8, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 25], "paper": [0, 1, 2, 3, 5, 10, 11, 13, 15, 17, 22], "clear": [0, 1], "comment": 0, "refer": [0, 1, 3, 9, 10, 13], "more": [0, 1, 2, 3, 10, 11, 13, 19, 20, 22, 23, 24], "below": [0, 3, 4, 5], "abov": [0, 3, 10, 11, 19], "all": [0, 1, 2, 3, 4, 12, 13, 15, 17, 19, 20, 22, 23, 25], "try": [0, 1, 5, 13, 24], "follow": [0, 1, 3, 4, 5, 6, 7, 8, 10, 13, 14, 23, 24], "googl": [0, 1, 10, 19, 25], "format": [0, 1, 2, 4, 5, 9, 10, 13, 18, 20, 22, 23], "napoleon": 0, "exampl": [0, 2, 3, 5, 6, 7, 8, 11, 12, 13, 15, 16, 20, 22, 23, 24], "styleguid": 0, "easi": 0, "sphinx": 0, "document": [0, 3, 5, 11, 12, 14], "And": [0, 1, 13, 14, 17], "feel": [0, 2], "free": [0, 2, 18], "autodoc": 0, "api": 0, "rst": 0, "file": [0, 1, 3, 4, 5, 6, 10, 11, 12, 13, 16, 18, 20, 22, 23, 24], "doc": [0, 2, 6, 7, 20, 22, 23], "sourc": [0, 3, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24], "folder": [0, 1, 4, 5, 13, 22, 24], "you": [0, 2, 4, 5, 8, 9, 11, 13, 14, 17, 22, 23, 24, 25], "addit": [0, 1, 3, 5, 9, 10, 15, 17, 20, 22, 23], "look": [0, 1, 5, 10, 11, 12, 14, 17, 23, 24], "right": 0, "how": [0, 2, 4, 5, 9, 13, 14, 16, 17, 24], "build": [0, 1, 9, 10, 15, 18, 19, 24], "local": [0, 4, 5, 7], "cd": [0, 3, 7, 13, 14, 24], "instal": [0, 4, 5, 7, 8, 9, 11, 12, 13, 15], "some": [0, 4, 8, 13, 14, 15, 20, 22, 23, 24], "depend": [0, 1, 2, 9, 13, 15, 17, 18], "necessari": [0, 1, 3, 8, 15, 19, 22, 23, 24], "recommonmark": 0, "sphinx_rtd_them": 0, "sphinxcontrib": 0, "bibtex": 0, "pip": [0, 1, 4, 7, 11, 12, 13, 14, 24], "requir": [0, 1, 2, 3, 6, 10, 14, 15, 17, 20, 22, 24], "txt": [0, 1, 3, 4, 5, 6, 10, 11, 12, 13, 14, 23, 24], "html": [0, 22], "firefox": 0, "main": [0, 1, 14, 15, 20, 22, 23], "browser": 0, "choic": [0, 5, 16, 17, 20, 22, 23], "particular": [0, 17], "advic": [0, 1], "python": [0, 1, 3, 5, 10, 13, 14, 15, 22], "3": [0, 3, 4, 5, 7, 9, 10, 13, 15, 20, 22, 23], "type": [0, 1, 3, 5, 6, 9, 10, 12, 13, 15, 16, 17, 18, 19, 20, 23], "modul": [0, 1, 2, 9, 15], "convent": 0, "except": [0, 1, 13, 18, 20, 22, 23], "us": [0, 2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23, 24], "instead": [0, 1, 2, 5, 13, 15, 17, 20, 22, 23], "union": 0, "readabl": 0, "For": [0, 1, 2, 3, 4, 5, 19, 22, 24], "extern": 0, "full": [0, 1, 3, 5, 10, 17, 18, 20, 22, 23], "import": [0, 1, 5, 6, 13], "common": [0, 1, 5, 9], "abbrevi": 0, "e": [0, 4, 9, 13, 14, 18, 22, 25], "g": [0, 4, 5, 7, 9, 13, 14, 22], "np": 0, "ar": [0, 2, 3, 4, 5, 6, 8, 9, 10, 13, 14, 15, 18, 19, 20, 22, 23, 24, 25], "accept": [0, 2, 19, 20, 22, 23, 24], "torch": [0, 7, 10, 15, 17, 22], "tensor": [0, 15, 16, 17, 19], "option": [0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 14, 15, 16, 17, 18, 19, 20, 22, 23], "don": [0, 1, 13], "t": [0, 1, 5, 6, 10, 13, 17, 19, 25], "tic": 0, "like": [0, 3, 5, 11, 12, 13, 19, 23], "str": [0, 1, 3, 13, 15, 16, 17, 18, 19], "direct": [0, 5, 19], "obj": [0, 15], "handl": [0, 1, 4, 5, 13, 15], "veri": [0, 1, 2, 10, 24], "well": [0, 1, 3, 4, 5, 10, 22], "without": [0, 4, 5, 6, 9, 17, 22, 24], "help": [0, 1, 4, 5, 13, 14, 23, 24], "so": [0, 1, 5, 10, 13, 22], "avoid": [0, 1, 2, 22], "clutter": 0, "support": [0, 2, 3, 4, 9, 15, 17, 22], "multipl": [0, 1, 2, 3, 13, 15, 16, 17, 22, 23], "return": [0, 1, 6, 13, 15, 17, 18, 19], "work": [0, 3, 5, 9, 11, 12, 13, 14, 19, 22], "still": [0, 1, 2], "def": [0, 1, 13], "foo": 0, "b": [0, 3, 4, 10, 19], "my": [0, 9], "arg": [0, 6, 13, 18, 19], "object": [0, 1, 3, 15, 16, 18, 19, 20, 22], "someth": 0, "anoth": [0, 15], "thing": [0, 1, 2], "rather": [0, 1, 10], "long": [0, 1, 3, 5, 15], "descript": [0, 4], "spill": 0, "over": [0, 1, 3, 5, 6, 8, 10, 13, 15, 17, 19, 22, 23], "cite": [0, 5, 14], "directli": [0, 1, 3, 5, 17, 23], "link": [0, 1, 4, 5, 11, 13], "entri": [0, 1, 20, 22, 23], "ref": [0, 22], "bib": 0, "attent": [0, 2, 3, 4, 5, 6, 9, 12, 13, 15, 19, 23, 25], "need": [0, 1, 2, 3, 4, 5, 6, 8, 10, 13, 14, 17, 22, 24, 25], "visit": [0, 13], "arxiv": [0, 1, 22, 23, 25], "choos": [0, 13], "bibtext": 0, "search": [0, 5, 9, 13, 19, 24], "ctrl": 0, "f": [0, 4, 5, 6, 13], "dblp": 0, "journal": 0, "corr": [0, 25], "vaswanispujgkp17": 0, "find": [0, 5, 13, 14], "copi": [0, 1, 3, 4, 5, 13, 15, 16, 17, 22, 23], "past": [0, 1, 10, 22], "citat": [0, 9], "Then": [0, 8, 13, 15, 17, 24], "howev": [0, 1, 2, 4, 5, 13, 15, 17], "better": [0, 1, 2, 5, 10, 20, 22, 23], "than": [0, 1, 2, 3, 7, 10, 13, 19, 20, 22, 23, 24], "noth": [0, 15], "shape": [0, 19], "prefer": [0, 1, 10], "c": [0, 1, 5, 10, 11, 12, 17, 21], "read": [0, 1, 13, 14, 18], "allow": [0, 1, 2, 3, 5, 16, 22], "x": [0, 1, 5, 6, 8, 10, 11, 15, 17, 19, 22], "multplic": 0, "few": [0, 1, 2, 13], "variat": 0, "parenthes": 0, "allennlp": 0, "exactli": 0, "fairseq": [0, 1, 20, 22], "singl": [0, 1, 6, 7, 13, 15, 18, 20, 22, 23, 24], "tick": 0, "again": [0, 13], "differ": [0, 4, 5, 6, 9, 13, 17, 18, 23], "unnecessari": 0, "space": [0, 1, 13, 22, 24], "charact": [0, 1, 11, 12, 20, 22, 23], "capit": 0, "punctuat": [0, 13], "multi": [0, 4, 9, 17], "line": [0, 1, 3, 4, 5, 6, 8, 10, 11, 12, 13, 16, 20, 22, 23, 24], "blank": [0, 1, 10, 13, 20, 22], "after": [0, 1, 3, 5, 13, 17, 19, 22], "close": [0, 1, 13, 20, 22, 23], "quot": 0, "Not": [0, 1], "note": [0, 1, 2, 4, 5, 8, 9, 10, 13, 19, 24], "least": [0, 1, 4], "focu": 0, "content": [0, 1, 4, 23, 24], "rememb": 0, "consist": [0, 1, 11, 17, 24], "good": [0, 1, 10, 13, 22], "Be": 0, "sensibl": [0, 1], "about": [0, 1, 6], "gener": [0, 3, 4, 5, 8, 9, 10, 12, 13, 15, 16, 17, 19, 23, 24, 25], "one": [0, 1, 2, 3, 5, 6, 10, 11, 12, 13, 17, 20, 22, 23, 24], "stand": 0, "alon": 0, "summari": [0, 5, 19, 23], "per": [0, 1, 2, 3, 5, 10, 11, 12, 13, 20, 22, 23, 24], "sometim": [0, 1], "": [0, 4, 5, 7, 8, 9, 10, 11, 13, 19, 20, 22, 23, 24, 25], "cut": [0, 6], "an": [0, 1, 3, 4, 5, 6, 10, 11, 12, 13, 15, 16, 17, 20, 22, 23, 25], "extend": [0, 1, 5, 17], "It": [0, 1, 2, 4, 5, 8, 10, 11, 12, 13, 14, 15, 17, 18, 24], "alwai": [0, 1, 17], "have": [0, 1, 3, 4, 5, 7, 8, 10, 13, 15, 17, 19, 22, 24], "trail": 0, "yaml": [1, 3, 4, 5, 6, 7, 8, 20, 22, 23, 24], "partial": 1, "To": [1, 2, 3, 4, 5, 6, 10, 11, 12, 17, 24, 25], "overview": [1, 9], "quickstart": [1, 9, 14], "section": [1, 5, 6, 13], "tutori": [1, 4, 13, 14, 24], "As": [1, 4], "remind": [1, 2], "reli": [1, 2, 10], "torchtext": [1, 2], "5": [1, 3, 4, 5, 7, 8, 10, 11, 13, 22, 23], "version": [1, 4, 5, 7, 9, 11, 12, 13, 17, 18, 19], "field": [1, 5, 15], "rawfield": 1, "multifield": 1, "which": [1, 2, 3, 4, 5, 10, 15, 16, 17, 19, 22, 24], "were": [1, 2, 24], "deprec": [1, 23], "In": [1, 3, 5, 6, 13, 17, 23, 25], "order": [1, 10], "old": [1, 2, 13], "mimic": [1, 10], "those": [1, 10], "result": [1, 3, 5, 6, 10, 13, 18, 22], "newer": 1, "12": [1, 3, 5, 10, 20, 22, 23], "13": [1, 5], "14": [1, 8, 22], "convers": [1, 4, 11, 12, 19], "elimin": 1, "complet": [1, 4, 11, 19], "perfom": [1, 22], "tool": [1, 2, 4, 10, 13], "convertv2": [1, 2], "_": [1, 2, 4, 6, 8, 10, 11, 13, 17, 24], "v2model": 1, "myoldmodel": 1, "pt": [1, 3, 4, 6, 7, 8, 10, 11, 12, 13, 22, 23, 24], "v3model": 1, "newmodel": 1, "The": [1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 24], "longer": [1, 2, 5, 23], "kei": [1, 13, 17, 22], "replac": [1, 4, 13, 19, 20, 22, 23], "vocab": [1, 2, 3, 4, 6, 8, 9, 10, 15, 16, 17, 19, 24], "rnn_size": [1, 2, 10, 13], "now": [1, 2, 5, 13, 24], "hidden_s": [1, 2, 3, 5, 8, 17, 22], "enc_rnn_siz": [1, 2, 12], "enc_hid_s": [1, 2, 22], "dec_rnn_siz": [1, 2, 12], "dec_hid_s": [1, 2, 22], "A": [1, 3, 4, 5, 10, 11, 12, 15, 16, 17, 22, 25], "add_qkvbia": [1, 2, 17, 22], "true": [1, 2, 3, 4, 5, 6, 8, 10, 13, 15, 16, 17, 19, 20, 22, 23], "default": [1, 2, 8, 10, 12, 13, 15, 17, 18, 20, 21, 22, 23, 24], "fals": [1, 2, 3, 5, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24], "gpt2": 1, "languag": [1, 5, 8, 9, 10, 20, 22, 23], "lm": [1, 6, 15, 22], "where": [1, 3, 4, 5, 8, 10, 13, 16, 17, 19, 20, 22, 23, 24], "onli": [1, 2, 3, 5, 6, 10, 13, 15, 16, 17, 19, 20, 22, 23], "unk": [1, 19, 20, 22, 23], "flag": [1, 3, 5, 8, 15, 24], "structur": [1, 2, 3, 13, 17, 25], "sensit": [1, 10, 13], "hyperparamet": [1, 10, 13], "effect": [1, 5, 10, 17, 18, 20], "setup": [1, 8, 10, 14, 15, 17], "confirm": [1, 10], "replic": [1, 5, 10, 13, 17], "wmt": [1, 8, 10], "wmt17": [1, 9], "en": [1, 8, 9, 10, 22], "de": [1, 8, 9, 10, 18], "opt": [1, 5, 6, 8, 14, 15, 16, 17, 18, 22, 24], "save_model": [1, 3, 5, 8, 10, 11, 12, 13, 22, 24], "mybasemodel": 1, "save_checkpoint_step": [1, 3, 8, 10, 13, 15, 22, 24], "10000": [1, 3, 5, 10, 13, 15, 22, 24], "valid_step": [1, 8, 10, 13, 15, 22, 24], "train_step": [1, 3, 5, 8, 10, 12, 13, 15, 22, 24], "200000": [1, 5, 10], "batch": [1, 2, 8, 10, 13, 15, 16, 17, 19, 22, 23], "bucket_s": [1, 2, 8, 16, 22], "262144": [1, 8, 22], "world_siz": [1, 5, 8, 10, 13, 22, 24], "4": [1, 2, 3, 5, 7, 9, 10, 12, 13, 20, 22, 23], "gpu_rank": [1, 3, 5, 8, 10, 11, 12, 13, 15, 22, 24], "num_work": [1, 2, 8, 22], "batch_typ": [1, 5, 7, 8, 10, 16, 22, 23], "batch_siz": [1, 3, 5, 7, 8, 10, 11, 12, 13, 16, 17, 19, 22, 23], "4096": [1, 5, 7, 8, 10, 15], "valid_batch_s": [1, 5, 8, 22], "2048": [1, 8, 10, 13, 16, 22], "accum_count": [1, 5, 8, 10, 15, 22], "accum_step": [1, 8, 15, 22], "optim": [1, 2, 5, 8, 9, 10, 12, 13], "model_dtyp": [1, 8, 15, 22], "fp16": [1, 2, 8, 15, 22, 23], "adam": [1, 5, 8, 10, 12, 13, 15, 22], "learning_r": [1, 3, 5, 8, 10, 11, 12, 13, 15, 22], "warmup_step": [1, 5, 8, 10, 22], "8000": [1, 5, 10, 13], "decay_method": [1, 5, 8, 10, 22], "noam": [1, 5, 8, 10, 22, 25], "adam_beta2": [1, 5, 8, 10, 22], "998": [1, 5, 7, 8, 10], "max_grad_norm": [1, 5, 8, 10, 11, 12, 15, 22], "label_smooth": [1, 5, 8, 10, 22], "param_init": [1, 5, 8, 10, 13, 22], "param_init_glorot": [1, 5, 8, 10, 13, 22], "encoder_typ": [1, 3, 5, 6, 8, 10, 11, 13, 22], "decoder_typ": [1, 3, 5, 6, 8, 10, 13, 22], "position_encod": [1, 5, 8, 10, 13, 17, 22], "enc_lay": [1, 8, 12, 22], "6": [1, 3, 8, 10], "dec_lay": [1, 8, 12, 22], "8": [1, 2, 3, 5, 8, 10, 12, 13, 15, 22, 23], "512": [1, 4, 5, 8, 10, 12, 13, 22], "word_vec_s": [1, 5, 8, 10, 11, 13, 17, 22], "transformer_ff": [1, 8, 10, 13, 22], "dropout_step": [1, 8, 15, 22], "dropout": [1, 5, 8, 10, 12, 13, 15, 17, 20, 22, 23], "attention_dropout": [1, 5, 8, 15, 17, 22], "here": [1, 2, 4, 5, 6, 10, 13, 14, 19, 24], "most": [1, 2, 5, 13, 15, 19, 20, 22, 23], "paramet": [1, 3, 5, 6, 8, 10, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24], "mean": [1, 2, 5, 10, 17, 18, 22, 24], "correct": [1, 10, 13, 15], "initi": [1, 3, 5, 9, 10, 13, 15, 16, 17, 18, 19, 20], "sinusoid": [1, 10, 17, 22], "each": [1, 2, 3, 4, 10, 13, 16, 17, 19, 20, 22, 23, 24], "rate": [1, 9, 10, 12, 15], "number": [1, 2, 3, 5, 10, 13, 15, 16, 17, 19, 20, 22, 23, 24], "sentenc": [1, 3, 5, 10, 19, 20, 22, 23, 24], "comput": [1, 2, 3, 5, 8, 10, 15, 17, 22, 23], "gradient": [1, 5, 10, 15, 22], "four": [1, 10, 11], "label": [1, 10, 11, 12, 15, 22], "smooth": [1, 7, 10, 20, 22, 23], "loss": [1, 5, 9, 10, 22], "batch_size_multipl": [1, 8, 16, 22], "vocab_size_multipl": [1, 22], "num": [1, 2], "worker": [1, 2], "dure": [1, 2, 3, 4, 5, 17, 18, 22, 23], "decai": [1, 2, 15, 22], "system": [1, 2, 3, 11, 12, 19, 22, 25], "max_relative_posit": [1, 17, 22], "20": [1, 2, 5, 6, 7, 11, 13, 20, 22, 23], "fast": [1, 2, 7, 10], "ctranslate2": [1, 2, 4, 15], "basic": [1, 5, 6], "stem": 1, "origin": [1, 2, 4, 13, 15, 22], "even": 1, "sinusoidalinterleav": [1, 17, 22], "sinusoidalconcat": [1, 22], "position_encoding_typ": [1, 17, 22], "forget": 1, "mode": [1, 6, 10, 20, 22, 23], "shaw": 1, "http": [1, 3, 4, 5, 7, 10, 11, 12, 14, 22, 23, 24, 25], "org": [1, 7, 14, 22, 23, 25], "ab": [1, 22, 23, 25], "1803": [1, 22], "02155": [1, 22], "n": [1, 2, 4, 5, 13, 17, 19, 20, 22, 23, 24, 25], "16": [1, 3, 5, 13, 19, 22, 25], "32": [1, 3, 22], "see": [1, 5, 6, 11, 13, 15, 17, 18, 19, 20, 22, 24, 25], "rope": 1, "2104": [1, 22], "09864": 1, "mpt": 1, "7b": 1, "2108": 1, "12409": 1, "both": [1, 10, 19, 22, 24], "case": [1, 2, 3, 7, 15, 17, 20, 22, 23], "nutshel": 1, "time": [1, 10, 12, 13, 15, 19, 20, 22, 23], "write": [1, 4, 13, 15], "manag": [1, 13, 15], "wherea": [1, 19, 22], "self": [1, 17, 18, 19, 22], "sure": [1, 4, 5, 10, 13, 19], "export": [1, 10, 13], "cuda_visible_devic": [1, 10, 13], "want": [1, 2, 8, 10, 13, 23, 24], "id": [1, 10, 18, 19, 20, 22], "o": [1, 5, 10, 11, 12, 13], "node": [1, 3, 10, 15, 17, 22], "warn": [1, 10, 11, 12, 13, 16, 20, 22, 23], "distribut": [1, 15, 17, 19, 20, 22, 23], "ha": [1, 2, 5, 13, 19, 22, 24], "been": [1, 4, 13, 19, 24], "properli": [1, 4], "re": [1, 7, 10, 13, 19], "implement": [1, 2, 3, 5, 10, 13, 15, 17, 22, 24], "sinc": [1, 5, 10, 13, 17], "master_ip": [1, 10, 22], "master_port": [1, 10, 22], "second": [1, 3, 10, 12, 15, 17, 18], "accumul": [1, 5, 10, 15, 22], "network": [1, 5, 9, 10, 12, 13, 17, 25], "card": [1, 4, 10], "gbp": [1, 10], "suggest": [1, 10, 22], "higher": [1, 10, 13, 19, 23], "minim": [1, 10], "inter": [1, 10], "legaci": [1, 2, 4, 5, 11, 12, 13], "sever": [1, 10, 17, 19], "couldn": 1, "them": [1, 3, 4, 10, 13, 17, 22], "exclus": [1, 10], "nvidia": [1, 7, 10, 22], "smi": [1, 10], "produc": [1, 2, 3, 10, 12, 19, 20, 22, 23], "consum": [1, 10], "n_gpu": [1, 10, 15], "process": [1, 2, 3, 5, 10, 13, 15, 18, 20, 22, 24], "spawn": [1, 2, 10], "host": [1, 10], "queue": [1, 10, 20], "next": [1, 10, 13, 15, 19, 23], "benefici": [1, 10], "wall": [1, 10], "memori": [1, 10, 13, 15, 18], "shard": [1, 10, 13, 22], "advanc": [1, 3, 10, 14, 17, 19, 22, 24], "codebas": [1, 2], "becaus": [1, 3, 10, 17], "move": [1, 18, 22], "devic": [1, 19, 23], "later": 1, "henc": [1, 3, 6, 11], "step": [1, 3, 5, 7, 9, 13, 14, 15, 17, 19, 22, 23], "onmt_train": [1, 6, 10, 11, 12, 13, 24], "execut": [1, 8, 20, 22], "mkdir": [1, 10], "glove_dir": [1, 10], "wget": [1, 10, 11, 12, 24], "nlp": [1, 3, 10], "stanford": [1, 10], "edu": [1, 10, 11, 12], "6b": [1, 10], "zip": [1, 10, 13], "unzip": [1, 10, 13], "d": [1, 3, 5, 6, 10, 11, 13, 17, 21, 25], "adapt": [1, 5, 12], "your_config": 1, "config": [1, 3, 4, 5, 6, 7, 8, 18, 20, 21, 22, 23, 24], "decod": [1, 3, 4, 5, 6, 9, 10, 12, 13, 15, 20, 24], "side": [1, 4, 5, 15, 18, 20, 22, 23], "both_embed": [1, 22], "100d": [1, 10], "src": [1, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24], "tgt": [1, 3, 5, 6, 8, 10, 11, 12, 15, 16, 17, 18, 20, 22, 23, 24], "separ": [1, 2, 3, 10, 13, 17, 23, 24], "src_embed": [1, 22], "tgt_embed": [1, 22], "word2vec": [1, 10, 22], "embeddings_typ": [1, 22], "dimens": [1, 3, 5, 17, 19, 22], "100": [1, 3, 5, 8, 10, 12, 19], "save": [1, 4, 6, 13, 15, 20, 22, 23, 24], "save_data": [1, 3, 5, 8, 10, 11, 12, 13, 20, 22, 24], "enc_embed": 1, "dec_embed": 1, "freeze_word_vecs_enc": [1, 22], "freeze_word_vecs_dec": [1, 22], "freez": [1, 17, 22], "specifi": [1, 6, 10, 13, 15, 17, 20, 22, 23, 24], "onmt_transl": [1, 5, 6, 8, 11, 12, 13, 24], "command": [1, 4, 5, 8, 10, 11, 13], "model1_seed1": 1, "model2_seed2": 1, "bear": [1, 10], "mind": [1, 10], "must": [1, 3, 6, 10, 17, 18, 20, 22, 23], "share": [1, 5, 6, 10, 13, 20, 22, 23], "natur": [1, 5], "introduc": [1, 5, 10], "own": 1, "ll": [1, 10, 13], "sequenti": [1, 16], "take": [1, 7, 10, 11, 14, 15, 17, 20, 22, 23], "corpu": [1, 5, 6, 8, 10, 16, 20, 22, 23, 24], "worri": 1, "homogen": 1, "heterogen": 1, "bucket": [1, 16, 22], "mechan": [1, 3, 5, 15, 17], "reason": 1, "sort": [1, 16, 18], "yield": [1, 16], "random": [1, 9, 13, 20, 22], "7": [1, 3, 4, 10, 11, 17, 22], "corpus_1": [1, 6, 24], "path_src": [1, 3, 5, 6, 8, 24], "toi": [1, 3, 11, 12, 24], "end": [1, 3, 19, 24], "train1": 1, "path_tgt": [1, 3, 5, 8, 24], "corpus_2": 1, "valid": [1, 3, 5, 6, 8, 10, 13, 15, 16, 20, 22, 23, 24], "val": [1, 3, 5, 11, 12, 13, 24], "seq2seq": [1, 19, 22], "wa": [1, 5, 10], "bo": [1, 19, 20, 22], "pad": [1, 15, 17, 19, 20, 22], "eo": [1, 19, 20, 22], "behavior": [1, 13], "group": [1, 3, 15, 22, 23, 24], "specila": 1, "narg": 1, "defaulttoken": 1, "srctok1": 1, "srctok2": 1, "srctok3": 1, "srctokn": 1, "tgttok1": 1, "tgttok2": 1, "tgttokm": 1, "But": 1, "said": 1, "eg": 1, "nllb": [1, 22], "200": [1, 10, 15, 20, 22, 23], "llama": 1, "exist": [1, 2, 5, 20, 22, 23, 24], "ex": [1, 4, 20, 22, 23], "fact": 1, "never": [1, 19], "At": [1, 22], "There": [1, 3, 10], "conflict": 1, "forc": [1, 19, 23], "0x00": 1, "pyonmttok": [1, 9, 20, 22, 23], "nbest": 1, "alpha": [1, 5, 19, 23], "src_subword_typ": [1, 6, 20, 22, 23], "src_subword_model": [1, 6, 8, 20, 22, 23], "spm": 1, "tgt_subword_typ": [1, 20, 22, 23], "tgt_subword_model": [1, 8, 20, 22, 23], "candid": [1, 20, 22, 23], "subword_nbest": 1, "subword_alpha": 1, "src_onmttok_kwarg": [1, 6, 20, 22, 23], "none": [1, 7, 8, 15, 16, 17, 18, 19, 20, 22, 23], "spacer_annot": 1, "tgt_onmttok_kwarg": [1, 20, 22, 23], "onmt_token": [1, 6, 20, 22, 23], "other": [1, 2, 4, 8, 13, 15, 19, 20, 22, 23, 24, 25], "method": [1, 2, 4, 5, 6, 15, 17, 22], "dedic": [1, 16], "detail": [1, 6, 11, 14, 20, 22, 24], "lucki": 1, "dai": [1, 25], "alreadi": [1, 6], "easili": 1, "everi": [1, 5, 10, 15, 16, 17, 22, 23], "found": [1, 5, 6], "filtertoolong": [1, 3, 5, 8, 20, 22, 23], "misc": 1, "filtertoolongtransform": 1, "src_seq_length": [1, 3, 5, 8, 13, 20, 22, 23], "maximum": [1, 5, 20, 22, 23], "sequenc": [1, 3, 5, 6, 13, 15, 17, 18, 19, 20, 22, 23, 25], "tgt_seq_length": [1, 3, 5, 8, 11, 13, 20, 22, 23], "prefixtransform": 1, "src_prefix": [1, 20, 22, 23], "tgt_prefix": [1, 20, 22, 23], "__some_src_prefix__": 1, "__some_tgt_prefix__": 1, "uniqu": 1, "oppos": 1, "come": 1, "given": [1, 2, 3, 10, 11, 12, 18], "spa_latn": 1, "tgt_file_prefix": [1, 19, 23], "suffixtransform": 1, "src_suffix": [1, 20, 22, 23], "tgt_suffix": [1, 20, 22, 23], "__some_src_suffix__": 1, "__some_tgt_suffix__": 1, "uppercasetransform": 1, "present": [1, 5], "cap": [1, 13], "string": [1, 13, 17, 20, 22, 23], "strip": [1, 5, 13], "diacrit": 1, "accent": 1, "usual": [1, 6, 24], "desir": [1, 8], "although": [1, 13, 17], "ratio": [1, 7, 8, 13, 19, 20, 22, 23], "upper_corpus_ratio": [1, 20, 22, 23], "01": [1, 12, 20, 22, 23], "normalizetransform": 1, "rule": [1, 3, 22], "mose": 1, "src_lang": [1, 20, 22, 23], "cz": 1, "fr": 1, "tgt_lang": [1, 20, 22, 23], "penn": [1, 20, 22, 23], "substitut": [1, 20, 22, 23], "norm_quote_comma": [1, 20, 22, 23], "quotat": [1, 20, 22, 23], "comma": [1, 20, 22, 23], "norm_numb": [1, 20, 22, 23], "pre_replace_unicode_punct": [1, 20, 22, 23], "unicod": [1, 20, 22, 23], "punct": [1, 20, 22, 23], "post_remove_control_char": [1, 20, 22, 23], "remov": [1, 2, 5, 6, 13, 20, 22, 23], "control": [1, 15, 20, 22, 23], "char": [1, 20, 22, 23], "cleantransform": 1, "src_eq_tgt": [1, 20, 22, 23], "same_char": [1, 20, 22, 23], "repeat": [1, 5, 13, 19, 23], "same_word": [1, 20, 22, 23], "script_ok": 1, "contain": [1, 4, 6, 10, 11, 12, 17, 18, 19, 24], "belong": 1, "latin": [1, 13, 20, 22, 23], "script_nok": 1, "src_tgt_ratio": [1, 20, 22, 23], "ration": 1, "avg_tok_min": [1, 20, 22, 23], "avg_tok_max": [1, 20, 22, 23], "lang_id": 1, "detect": 1, "docifi": [1, 9], "docifytransform": 1, "concaten": [1, 22], "delimit": [1, 3, 20, 22, 23], "pre": [1, 10, 15, 18, 19], "requisit": 1, "empti": [1, 6, 8, 16, 17, 19, 20, 22], "stori": 1, "doc_length": [1, 20, 22, 23], "max": [1, 2, 3, 13, 15, 17, 19, 20, 22, 23], "max_context": [1, 20, 22, 23], "ie": 1, "precaut": 1, "linearli": 1, "stride": [1, 12, 16], "fuzzymatch": [1, 9], "fuzzymatchtransform": 1, "describ": [1, 2, 4, 5, 13, 14, 18, 22], "machin": [1, 5, 14, 17, 19, 24, 25], "current": [1, 4, 5, 10, 15, 16, 17, 19, 22], "tm": [1, 20, 22, 23], "should": [1, 2, 3, 5, 8, 10, 13, 15, 16, 17, 19, 22, 24], "flat": [1, 20, 22, 23], "text": [1, 4, 9, 16, 17, 19, 20, 22, 23, 25], "intens": 1, "offer": 1, "achiev": [1, 5], "overhead": 1, "spec": 1, "mai": [1, 2, 10, 15, 16, 18, 19, 20, 22], "experi": [1, 5, 20, 22, 23], "bucket_size_init": [1, 16, 22], "bucket_size_incr": [1, 16, 22], "increas": [1, 2, 3, 13, 17], "prefetch_factor": [1, 22], "wait": [1, 22], "size": [1, 2, 3, 5, 12, 13, 15, 16, 17, 19, 20, 22, 23], "200k": 1, "250k": 1, "unit": [1, 3, 17, 24], "enough": [1, 4], "suffici": [1, 2], "short": [1, 4, 12], "bit": [1, 23], "n_sampl": [1, 4, 5, 6, 7, 8, 20, 22, 24], "tm_path": [1, 20, 22, 23], "path": [1, 3, 6, 10, 11, 12, 13, 17, 18, 19, 20, 22, 23, 24], "fuzzy_corpus_ratio": [1, 20, 22, 23], "fuzzy_threshold": [1, 20, 22, 23], "threshold": [1, 20, 22, 23], "70": [1, 3, 13, 20, 22, 23], "tm_delimit": [1, 20, 22, 23], "fuzzy_token": [1, 20, 22, 23], "fuzzymatch_min_length": [1, 20, 22, 23], "min": [1, 20, 22, 23], "fuzzymatch_max_length": [1, 20, 22, 23], "inlinetag": [1, 9], "inlinetagstransform": 1, "placehold": 1, "kind": 1, "pair": [1, 3, 5, 10, 13, 15, 16, 18, 20, 22, 23], "open": [1, 13, 14, 20, 22, 23], "isol": [1, 20, 22, 23], "standalon": 1, "tab": [1, 23], "dictionari": [1, 5, 15, 17, 19, 20, 22, 23], "term": [1, 10, 15, 17, 20, 22, 23, 24], "phrase": 1, "30k": 1, "recommend": [1, 2, 7, 22], "user": [1, 2, 15, 18], "defin": [1, 3, 5, 6, 8, 15, 16, 17, 20, 22, 23], "tags_dictionary_path": [1, 20, 22, 23], "tags_corpus_ratio": [1, 20, 22, 23], "max_tag": [1, 20, 22, 23], "paired_stag": [1, 20, 22, 23], "ph": 1, "beg": 1, "paired_etag": [1, 20, 22, 23], "isolated_tag": [1, 20, 22, 23], "std": 1, "src_delimit": [1, 20, 22, 23], "src_subword_nbest": [1, 8, 20, 22, 23], "tgt_subword_nbest": [1, 8, 20, 22, 23], "src_subword_alpha": [1, 8, 20, 22, 23], "probabl": [1, 10, 17, 19, 20, 22, 23], "tgt_subword_alpha": [1, 8, 20, 22, 23], "onmttokenizertransform": 1, "kwarg": [1, 17], "sentencepiecetransform": 1, "bpetransform": 1, "compos": 1, "part": [1, 3, 5, 6, 13, 19], "denois": 1, "comprehens": 1, "These": [1, 2, 3, 5, 13, 17, 19], "permute_sent_ratio": [1, 20, 22, 23], "proport": [1, 20, 22, 23], "permut": [1, 20, 22, 23], "boundari": [1, 5, 20, 22, 23], "rotate_ratio": [1, 20, 22, 23], "input": [1, 2, 3, 5, 6, 13, 15, 16, 17, 18, 19, 20, 22, 23, 25], "insert_ratio": [1, 20, 22, 23], "insert": [1, 20, 22, 23], "random_ratio": [1, 20, 22, 23], "mask_ratio": [1, 20, 22, 23], "mask_length": [1, 20, 22, 23], "window": [1, 12, 15, 20, 22, 23], "span": [1, 20, 22, 23], "poisson": [1, 20, 22, 23], "poisson_lambda": [1, 20, 22, 23], "lambda": [1, 13, 20, 22, 23], "valu": [1, 2, 3, 4, 5, 8, 10, 15, 17, 18, 19, 20, 22, 23], "replace_length": [1, 20, 22, 23], "switchouttransform": 1, "switchout_temperatur": [1, 20, 22, 23], "temperatur": [1, 19, 20, 22, 23], "tokendrop": [1, 20, 22, 23], "tokendroptransform": 1, "tokendrop_temperatur": [1, 20, 22, 23], "delet": [1, 13, 20, 22, 23], "tokenmask": [1, 20, 22, 23], "tokenmasktransform": 1, "tokenmask_temperatur": [1, 20, 22, 23], "inherit": 1, "instanc": [1, 4, 15, 17, 19], "templat": 1, "register_transform": 1, "out": [1, 2, 3, 5, 6, 13, 15, 17], "too": [1, 3, 13, 19, 22], "classmethod": [1, 15, 16, 17], "add_opt": 1, "cl": [1, 15], "parser": [1, 13], "avalil": 1, "relat": [1, 8, 20, 22, 23], "add_argument_group": 1, "int": [1, 3, 13, 15, 16, 17, 18, 19], "_parse_opt": 1, "is_train": 1, "stat": [1, 13, 15, 22], "els": [1, 13], "len": [1, 13, 15, 17, 19], "filtertoolongstat": 1, "_repr_arg": 1, "repres": [1, 3, 24], "would": [1, 2, 19, 22], "pars": [1, 16, 17, 18], "happen": [1, 19, 20, 22], "log": [1, 4, 9, 15, 19], "wrapper": [1, 5, 15], "definit": [1, 3, 17], "automat": [1, 3, 5], "proper": [1, 18], "usabl": 1, "through": [1, 2, 3, 15], "could": [1, 10, 13, 19], "collect": [1, 13, 16], "statist": [1, 15, 22], "observablestat": 1, "rune": 1, "__slots__": 1, "__init__": [1, 18], "element": [1, 4, 16], "keep": [1, 13, 15, 18, 19, 22], "track": 1, "__slot__": 1, "lightweight": 1, "suppli": 1, "logic": 1, "overrid": [1, 17, 19, 20, 22], "__str__": 1, "messag": 1, "instanti": [1, 15], "pass": [1, 10, 15, 17, 18, 22], "correspond": [1, 16, 23], "gather": [1, 15], "report": [1, 13, 14, 15, 23], "dict": [1, 15, 16, 17, 18, 20, 22, 23], "form": [1, 5], "pharaoh": [1, 10], "inputt": [1, 16], "parallelcorpu": [1, 16], "consid": [1, 5, 13, 17], "futur": [1, 10], "customparallelcorpu": 1, "cf": [1, 2, 15, 22], "bigger": 1, "limit": [1, 23], "anmount": 1, "vram": 1, "principl": [1, 10], "layer": [1, 3, 4, 5, 10, 13, 15, 17, 22, 23, 24], "trainabl": [1, 15], "reduc": [1, 2, 10, 15], "amount": [1, 5, 13, 16, 22], "especi": 1, "3b": [1, 22], "lora_lay": [1, 22], "linear_valu": [1, 22], "linear_queri": [1, 22], "two": [1, 5, 10, 13, 17, 22], "lora_rank": [1, 22], "lora_dropout": [1, 22], "lora_alpha": [1, 22], "lora_embed": [1, 22], "compat": [1, 2, 13], "update_vocab": [1, 22], "bitsandbyt": 1, "enabl": [1, 4, 5, 6, 10, 17, 22, 23, 24], "quantiz": [1, 4, 23], "linear": [1, 2, 3, 13, 17, 22], "inform": [1, 3, 17, 22, 23], "com": [1, 3, 4, 5, 7, 12, 14, 17, 24], "timdettm": 1, "blog": 1, "post": 1, "huggingfac": 1, "co": 1, "hf": 1, "quant_lay": [1, 22], "w_1": 1, "w_2": 1, "positionwis": 1, "feed": [1, 4, 17, 22], "forward": [1, 4, 15, 17, 22], "moment": [1, 15, 22], "cannot": 1, "mix": [1, 7, 15, 16], "compress": [1, 4, 22], "todo": 1, "report_align": [1, 10, 19, 23], "call": [1, 5, 10, 13, 17, 19], "output": [1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 22, 23, 24], "argmax": [1, 10, 13, 23], "last": [1, 10, 15, 17, 22], "behaviour": [1, 10], "empir": [1, 5, 10], "determin": [1, 10], "thei": [1, 4, 10, 13, 17, 19], "penultim": [1, 10], "slight": [1, 4, 6], "architectur": [1, 4, 10, 13, 22], "standard": [1, 5, 10, 17, 22, 23], "j": [1, 5, 10, 17, 25], "indic": [1, 3, 10, 13, 15, 17, 19, 20, 22, 23], "th": [1, 10], "da": [1, 10], "stimmt": [1, 10], "nicht": [1, 10], "gold_align": [1, 19, 23], "between": [1, 2, 3, 5, 6, 8, 10, 17, 20, 22, 23, 25], "gold": [1, 10, 19, 23], "assum": [1, 3, 5, 10, 11, 12, 13, 19], "evalu": [1, 9, 10, 13, 15, 24], "symetr": [1, 10], "bidirect": [1, 5, 10, 17, 22], "lilt": [1, 10], "qualiti": [1, 4, 10], "further": [1, 10, 20, 22], "improv": [1, 4, 10, 13, 15, 17, 19, 22, 25], "provid": [1, 2, 3, 4, 6, 10, 11, 12, 14, 23], "invok": [1, 10], "task": [1, 4, 6, 8, 9, 10, 16], "jointli": [1, 5, 10, 15, 17, 25], "preprocess": [1, 2, 5, 11, 12, 13, 18, 20, 22, 23], "giza": [1, 10], "path_align": 1, "incompat": 1, "joint": [1, 10], "pipelin": [1, 2, 20, 22, 23, 24], "modif": [1, 4, 15], "level": [1, 16, 20, 22, 23], "made": [1, 24], "invalid": [1, 20, 22, 23], "lambda_align": [1, 10, 15, 22], "05": [1, 5, 10, 17], "alignment_lay": [1, 10, 17, 22], "index": [1, 10, 13, 17], "alignment_head": [1, 10, 17, 22], "kept": [1, 10], "num_head": [1, 10], "full_context_align": [1, 10, 17, 22], "slow": [1, 2, 3, 10, 20, 23], "down": [1, 2, 10, 19, 20, 24], "tok": [1, 7, 10, 18], "map": [1, 4, 13, 15, 17, 20, 22, 23], "onmt_build_vocab": [1, 3, 5, 6, 8, 24], "reset_optim": [1, 22], "state": [1, 3, 5, 15, 17, 19, 22], "train_from": [1, 22], "incorpor": [1, 22], "append": [1, 13, 20, 22, 23], "actual": [1, 13, 19, 24], "textual": 1, "accord": [1, 2], "l": [1, 11, 13], "she": 1, "hard": 1, "prior": [1, 8, 20, 22], "featinfertransform": 1, "instac": 1, "n_src_feat": [1, 16, 20, 22, 23], "expect": [1, 6, 13, 15, 19], "src_feats_default": [1, 16, 20, 22, 23], "realli": 1, "annot": [1, 3, 13, 20, 22, 23], "appropri": [1, 3, 4, 19], "src_word_vec_s": [1, 3, 17, 22], "tgt_word_vec_s": [1, 3, 22], "feat_merg": [1, 17, 22], "vec": [1, 13], "feat_vec_s": [1, 13, 17, 22], "mayb": 1, "feat_vec_expon": [1, 17, 22], "ensur": [1, 13], "possibl": [1, 2, 18, 19, 20, 22, 23, 24], "concat": [1, 4, 17, 22], "dummi": 1, "inferfeat": [1, 9], "reversible_token": [1, 20, 22, 23], "joiner": [1, 20, 22, 23], "src_vocab": [1, 3, 5, 8, 17, 20, 22, 24], "exp": [1, 7, 22], "tgt_vocab": [1, 3, 5, 8, 20, 22, 24], "sum": [1, 15, 17, 19, 22], "rest": [1, 21], "serv": 1, "discuss": 1, "forum": [1, 14], "idea": [1, 10], "behind": 1, "point": [1, 5, 25], "receiv": [1, 2], "detoken": [1, 8, 18], "available_model": [1, 21], "conf": [1, 21], "json": [1, 4, 21], "along": [1, 13, 15], "models_root": 1, "manual": [1, 18, 19], "assign": [1, 23], "counter": 1, "ass": 1, "timeout": [1, 18], "interv": [1, 22], "unload": [1, 18], "reset": 1, "whether": [1, 15, 17, 18, 19, 22], "on_timeout": [1, 18], "everyth": 1, "to_cpu": [1, 18], "transfer": 1, "ram": [1, 13], "faster": [1, 17], "reload": 1, "translate_opt": [1, 4], "bool": [1, 3, 15, 16, 17, 18, 19], "ct2_translator_arg": [1, 18], "ct2_translate_batch_arg": [1, 18], "engin": 1, "appear": 1, "simultan": 1, "ct2_": 1, "_arg": 1, "ident": 1, "ct2_model": [1, 18], "model_0": 1, "600": 1, "beam_siz": [1, 3, 5, 6, 7, 8, 11, 19, 23], "wmtenfr": 1, "light": [1, 10], "model_root": [1, 18], "other_model": 1, "10": [1, 5, 6, 7, 13, 14, 22, 23, 25], "merg": [1, 4, 17, 22], "master": [1, 22, 24], "branch": [1, 2], "cp": 1, "path_to_my_model": 1, "ip": [1, 21, 22], "port": [1, 21, 22], "5000": [1, 3, 8, 15, 17, 20, 21, 22], "url_root": [1, 21], "optionn": 1, "explicit": 1, "librari": [1, 22], "configargpars": 1, "cor": 1, "22": [1, 6], "waitress": 1, "dockerfil": 1, "cuda10": 1, "cudnn7": 1, "runtim": 1, "workdir": 1, "usr": [1, 5], "app": 1, "cach": [1, 7], "dir": [1, 7, 17], "r": [1, 3, 5, 11, 13, 14, 17, 22, 25], "volum": 1, "cmd": 1, "imag": [1, 2, 9, 15], "opennmt_serv": 1, "rm": [1, 4, 13, 17, 22], "p": [1, 5, 6, 11, 17, 19, 23, 25], "fex": 1, "rout": 1, "bin": [1, 4, 5, 7], "127": 1, "curl": 1, "wmt14": 1, "de_acc_69": 1, "22_ppl_4": 1, "33_e9": 1, "involv": 1, "h": [1, 5, 10, 17, 20, 21, 22, 23], "applic": [1, 4], "model_id": [1, 18], "u2581di": 1, "u2581formen": 1, "kant": 1, "u2581": 1, "k": [1, 2, 5, 6, 19, 23], "u00f6r": 1, "ner": 1, "u2581d": 1, "u2581stahl": 1, "u": [1, 2, 4, 5, 6, 8], "u00df": 1, "statu": 1, "ok": [1, 3], "total": [1, 15, 22], "510261535644531": 1, "509992599487305": 1, "writing_src": 1, "0002689361572265625": 1, "v3": [2, 9], "releas": [2, 5], "doe": [2, 3, 4, 5, 9, 10, 13, 23], "anymor": 2, "checkpoint": [2, 8, 9, 13, 15, 22, 24], "slightli": [2, 4, 10, 13], "convert": [2, 4, 10, 13, 16, 18], "v2": [2, 9], "model": [2, 3, 4, 7, 9, 11, 12, 13, 14, 17, 19, 20], "dynam": [2, 6, 9, 16, 17, 23], "paradigm": 2, "appli": [2, 4, 5, 6, 9, 12, 15, 16, 17, 18, 19, 20, 22, 23], "fly": [2, 4, 6, 8, 9], "transform": [2, 3, 4, 5, 6, 7, 8, 9, 12, 14, 15, 16, 17, 24, 25], "data": [2, 9, 10, 11, 12, 13, 15, 19, 25], "advantag": 2, "amongst": 2, "drastic": [2, 5], "train": [2, 3, 4, 9, 11, 12, 13, 14, 15, 16, 17], "augment": [2, 20, 22, 23, 25], "manipul": [2, 15], "can": [2, 3, 4, 5, 6, 8, 9, 11, 13, 14, 16, 18, 19, 20, 22, 23, 24], "specif": [2, 4, 5, 9, 14, 16, 19, 20, 22, 24], "token": [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 24], "filter": [2, 3, 5, 8, 9, 13], "nois": [2, 9], "custom": [2, 4, 9, 15, 18, 22], "quit": [2, 24], "straightforward": 2, "thank": [2, 24], "load": [2, 6, 9, 10, 13, 15, 16, 17, 18, 22], "updat": [2, 9, 10, 15, 18, 19, 22], "readili": [2, 9], "avail": [2, 6, 9, 13, 15, 18, 22, 23], "queue_siz": 2, "pool_factor": 2, "adjust": [2, 3], "dataload": [2, 22], "gpu": [2, 3, 5, 7, 8, 9, 11, 12, 13, 15, 18, 19, 22, 23, 24], "1": [2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 22, 23, 25], "2": [2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 15, 20, 22, 23], "set": [2, 3, 4, 5, 6, 7, 8, 9, 10, 13, 15, 17, 18, 19, 20, 22, 23, 24], "bia": [2, 15, 17, 22], "q": [2, 17], "v": [2, 7, 9, 25], "nn": [2, 15, 17, 22], "multihead": 2, "renam": [2, 13], "convertv2_v3": 2, "store": [2, 6, 11, 12], "0": [2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23], "infer": [2, 6, 9, 11, 16, 19, 23], "translat": [2, 3, 5, 9, 11, 12, 13, 14, 15, 17, 18, 21, 25], "iter": [2, 6, 9, 15, 22], "trainer": [2, 9, 24], "length_penalti": [2, 5, 8, 19, 23], "avg": [2, 8, 17, 23], "bleu": [2, 7, 8, 13], "score": [2, 7, 9, 13, 15, 17, 18, 23], "compar": [2, 8, 13], "toolkit": [2, 8, 14], "featur": [2, 3, 4, 9, 12, 13, 14, 15, 17, 18, 25], "drop": 2, "v1": [2, 14], "audio": [2, 12], "video": [2, 9], "previou": [2, 19], "retain": 2, "extens": 2, "from": [2, 3, 4, 5, 6, 9, 11, 12, 13, 14, 15, 16, 17, 19, 22, 23, 24], "core": [2, 9, 15], "team": 2, "let": [2, 4, 5, 8], "know": [2, 8, 13], "what": [2, 9, 10, 11, 13, 15, 18], "think": 2, "cpu": [2, 7, 18, 23], "resourc": [2, 9], "power": 2, "ideal": 2, "2n": 2, "thread": [2, 20], "averag": [2, 3, 8, 9, 15, 17, 20, 22, 23, 25], "rel": [2, 9, 11, 12, 17, 22], "posit": [2, 4, 9, 10, 15, 17, 22], "encod": [2, 3, 5, 6, 9, 10, 12, 13, 15, 19, 24], "represent": [3, 12, 17, 22, 25], "ast": 3, "connect": [3, 13], "benefit": 3, "ggnn": [3, 17, 22], "jameschuanggg": [3, 17], "git": [3, 5, 7, 12, 13, 14, 17], "y": [3, 4, 5, 12, 13, 17], "li": [3, 17], "tarlow": [3, 17], "m": [3, 4, 5, 13, 14, 17, 25], "brockschmidt": [3, 17], "zemel": [3, 17], "program": 3, "equival": [3, 5, 22], "proof": 3, "dataflow": 3, "via": [3, 15, 17, 22, 25], "rewrit": 3, "That": [3, 13], "show": [3, 4, 5, 13], "problem": [3, 11, 19], "graphic": 3, "beyond": [3, 15], "rnn": [3, 5, 15, 17, 22], "sequence2sequ": 3, "get": [3, 4, 5, 11, 12, 13, 24, 25], "directori": [3, 4, 11, 12, 13, 18, 22], "throughout": [3, 11, 12], "download": [3, 9, 11, 12, 13, 24], "sibl": 3, "clone": [3, 5, 7, 13, 14, 18], "stevekommrusch": 3, "env": 3, "configur": [3, 4, 5, 6, 8, 9, 17, 24], "written": [3, 5, 8, 15, 24], "1000": [3, 13, 24], "30": [3, 15, 19, 22, 23], "cnndm": [3, 5], "weight": [3, 5, 8, 9, 15, 16, 17, 22, 23], "srcvocab": 3, "tgtvocab": 3, "start_decay_step": [3, 22], "learning_rate_decai": [3, 12, 22], "global_attent": [3, 5, 12, 22], "src_ggnn_size": [3, 17, 22], "larger": [3, 24], "plu": [3, 22], "hot": 3, "less": [3, 7, 13], "learn": [3, 5, 6, 9, 11, 12, 15, 17, 20, 22, 25], "state_dim": [3, 17, 22], "togeth": [3, 24], "embed": [3, 4, 5, 9, 13, 20], "64": [3, 10, 13, 22], "bridg": [3, 5, 22, 25], "n_edge_typ": [3, 17, 22], "9": [3, 4, 5, 6, 7, 11, 15, 22], "n_step": [3, 17, 22], "aggreg": 3, "hop": 3, "n_node": [3, 17, 22], "algebra": 3, "express": 3, "axiom": 3, "prove": 3, "model_step_10000": 3, "n_best": [3, 6, 18, 19, 23], "pred": [3, 7, 11, 12, 13, 22, 23], "test_beam5": 3, "translate5": 3, "leverag": 3, "interfac": [3, 15, 17], "much": [3, 13, 22], "nearal": 3, "edg": [3, 17, 22], "eot": 3, "equat": 3, "being": [3, 4], "extra": [3, 10, 14, 17, 22], "rang": [3, 15, 23], "9th": 3, "just": [3, 5, 13, 24], "non": [3, 17, 19, 22], "mathemat": 3, "matric": 3, "identifi": [3, 23], "certain": 3, "occur": [3, 4], "shown": 3, "remain": 3, "numer": [3, 15], "integ": [3, 19], "duplic": 3, "vector": [3, 13, 15, 17, 22], "up": [3, 5, 9, 13, 17, 23], "largest": 3, "creat": [3, 4, 9, 10, 13, 15, 24], "lower": [3, 13, 22], "bet": 3, "rnn_type": [3, 12, 17, 22], "recurr": [3, 9, 17], "lstm": [3, 5, 11, 12, 17, 22, 24], "bidir_edg": [3, 17, 22], "revers": [3, 17, 20, 22, 23], "bridge_extra_nod": [3, 17, 22], "1st": [3, 17], "stabil": [3, 15, 17], "foundat": 4, "instruct": [4, 5, 22], "round": 4, "lora": [4, 9, 22], "8bit": [4, 9, 22], "wise": 4, "normalis": 4, "rotari": [4, 9, 17, 22], "swiglu": 4, "activ": [4, 17, 22], "maxim": [4, 25], "context": [4, 10, 17, 20, 22, 23], "length": [4, 5, 8, 13, 15, 17, 19, 20, 22, 23], "repositori": [4, 5, 13], "replicate_vicuna": 4, "subdirectori": 4, "chekpoint": 4, "llama7b": 4, "genener": 4, "dataai": 4, "sampl": [4, 5, 6, 9, 11, 12, 19, 20, 22, 24], "tensorboard": [4, 6, 15, 22], "input_exampl": 4, "add_missing_kei": 4, "chatbot": 4, "gradio": 4, "procedur": [4, 5], "retriev": 4, "sentencepiec": [4, 8, 20, 22, 23], "offici": 4, "facebookresearch": 4, "convert_llama": 4, "python3": [4, 7], "model_dir": 4, "tokenizer_model": 4, "subword": [4, 9, 10], "extract": [4, 13], "newli": 4, "extract_vocabulari": 4, "out_fil": [4, 19], "alpaca": 4, "give": [4, 13, 22, 23], "three": [4, 17], "tip": [4, 9], "stai": 4, "healthi": 4, "eat": 4, "balanc": 4, "nutriti": 4, "diet": 4, "meal": 4, "inclus": 4, "varieti": [4, 11], "fruit": 4, "veget": 4, "lean": 4, "protein": 4, "whole": [4, 8, 19], "grain": 4, "fat": 4, "bodi": 4, "essenti": [4, 19], "nutrient": 4, "best": [4, 13, 19, 23], "prevent": [4, 5, 19, 23, 24], "chronic": 4, "diseas": 4, "n2": 4, "engag": 4, "regular": [4, 9, 10, 15, 20, 22, 23], "physic": 4, "exercis": 4, "crucial": 4, "maintain": [4, 19], "strong": 4, "bone": 4, "muscl": 4, "cardiovascular": 4, "health": 4, "aim": 4, "150": [4, 8, 11], "minut": 4, "moder": 4, "aerob": [4, 24], "75": [4, 5], "vigor": 4, "week": 4, "n3": 4, "sleep": 4, "mental": 4, "regul": 4, "mood": 4, "cognit": 4, "growth": 4, "immun": 4, "hour": [4, 7], "night": 4, "flatten": [4, 13], "plain": [4, 16], "moreov": 4, "symbol": [4, 6], "act": 4, "break": [4, 9, 13], "world": [4, 13], "newlin": [4, 13], "51751": 4, "28800": 4, "prompt": [4, 13], "instrunct": 4, "pattern": 4, "propos": [4, 24], "answer": 4, "respons": [4, 15], "request": 4, "replicate_alpaca": 4, "overriden": 4, "launch": [4, 6], "nohup": 4, "finetenun": 4, "start": [4, 7, 15, 16, 18, 19, 20, 22, 24], "turn": [4, 13, 17, 22], "dump_sampl": [4, 20], "strictli": 4, "worth": 4, "he": [4, 24], "substr": 4, "0x0a": 4, "our": [4, 12, 13, 14, 19], "embd": 4, "scratch": 4, "ately": 4, "compl": 4, "te": 4, "inst": 4, "ruction": 4, "iv": [4, 9], "ing": 4, "bal": 4, "anc": 4, "nut": 4, "rit": 4, "iou": 4, "di": 4, "et": [4, 5, 22], "me": 4, "al": [4, 5, 22], "inclu": 4, "ruit": 4, "abl": 4, "gra": 4, "ins": 4, "ats": 4, "ri": 4, "ent": 4, "chron": 4, "ic": 4, "dise": 4, "ases": 4, "eng": 4, "ag": 4, "erc": 4, "ise": 4, "cru": 4, "cial": 4, "ones": 4, "mu": 4, "cle": 4, "ov": 4, "asc": 4, "ular": 4, "im": 4, "ate": 4, "aer": 4, "ob": 4, "vig": 4, "orou": 4, "reg": 4, "ulat": 4, "ood": 4, "cogn": 4, "itiv": 4, "imm": 4, "un": 4, "lora_weight": 4, "action": [4, 17, 19, 22], "base_model": 4, "finetuned_llama7b": 4, "onmt_step_4000": 4, "insid": 4, "obtain": 4, "examples_llama7b": 4, "paramat": 4, "release_model": 4, "concat_ct2": 4, "int8_float16": 4, "chat": 4, "bottom": 5, "abstract": [5, 17], "inproceed": [5, 14], "gehrmann2018bottom": 5, "titl": [5, 14], "author": [5, 13, 14], "gehrmann": 5, "sebastian": 5, "deng": [5, 14], "yuntian": [5, 14], "rush": [5, 14], "alexand": [5, 14], "booktitl": [5, 14], "proceed": 5, "2018": [5, 25], "confer": 5, "page": 5, "4098": 5, "4109": 5, "year": [5, 14], "dataset": [5, 6, 8, 9, 11, 13, 20, 22, 24], "access": 5, "split": [5, 13], "articl": 5, "australia": 5, "account": [5, 13], "deficit": 5, "shrunk": 5, "record": 5, "billion": 5, "dollar": 5, "lrb": 5, "rrb": 5, "june": 5, "quarter": 5, "due": [5, 13, 22], "soar": 5, "commod": 5, "price": 5, "figur": 5, "mondai": 5, "australian": 5, "narrow": 5, "sharpli": 5, "addition": [5, 17], "truncat": [5, 15, 22], "400": [5, 13], "target": [5, 6, 8, 10, 15, 17, 18, 20, 22, 23, 24], "surround": 5, "tag": [5, 20, 22, 23], "w1": 5, "w2": 5, "w3": 5, "sed": [5, 7], "overwrit": [5, 20, 22, 24], "src_seq_length_trunc": [5, 22], "tgt_seq_length_trunc": [5, 22], "vocabulari": [5, 9, 10, 15, 17, 20, 22, 23, 24], "share_vocab": [5, 6, 20, 22], "similar": [5, 13, 17, 22], "signific": [5, 13], "copy_attn": [5, 15, 16, 17, 19, 22], "word": [5, 9, 17, 19, 20, 22, 23], "mlp": [5, 12, 17, 22], "bahdanau": [5, 17, 22, 25], "luong": [5, 17, 22, 25], "dot": [5, 17, 22], "share_embed": [5, 8, 22], "decreas": 5, "did": 5, "reuse_copy_attn": [5, 17, 22], "reus": [5, 17, 22], "copy_loss_by_seqlength": [5, 22], "divid": [5, 8, 15, 22, 23], "practic": 5, "penalti": [5, 8, 9, 15, 19], "final": [5, 8, 17, 19], "hidden": [5, 15, 17, 22, 24], "adagrad": [5, 22], "outperform": 5, "sgd": [5, 22], "coupl": 5, "adagrad_accumulator_init": [5, 22], "match": [5, 18, 20, 22, 23], "algorithm": [5, 15, 25], "tensorflow": [5, 22], "align": [5, 9, 15, 16, 17, 18, 19, 23, 25], "previous": 5, "dynamic_dict": 5, "128": 5, "dimension": [5, 17], "On": [5, 15], "brnn": [5, 11, 13, 22], "256": 5, "norm": [5, 15, 17, 22], "renorm": [5, 22], "exce": [5, 22], "src_vocab_s": [5, 22], "50000": [5, 22], "tgt_vocab_s": [5, 22], "15": [5, 6, 19, 25], "seed": [5, 8, 13, 19, 20, 22, 23], "777": 5, "model_transform": 5, "normal": [5, 8, 9, 10, 17], "beam": [5, 9, 13, 19, 24], "stepwise_penalti": [5, 19, 23], "coverage_penalti": [5, 19, 23], "beta": [5, 15, 19, 23], "coverag": [5, 15, 17, 19, 22, 23], "wu": [5, 23, 25], "block_ngram_repeat": [5, 19, 23], "trigram": 5, "ignore_when_block": [5, 19, 23], "testout": 5, "min_length": [5, 19, 23], "35": [5, 7], "verbos": [5, 6, 10, 11, 12, 13, 19, 22, 23, 24], "roug": [5, 13], "pyroug": 5, "gram": [5, 19], "typic": [5, 15, 20, 22], "sub": 5, "repo": [5, 13], "recurs": 5, "submodul": 5, "sebastiangehrmann": 5, "baselin": [5, 13, 22], "maco": 5, "pointer": [5, 17, 25], "perl": 5, "pl": 5, "might": 5, "simpl": [5, 15], "w": [5, 13, 17, 25], "fail": [5, 19], "sent_tag_verbatim": 5, "around": [5, 15, 17], "becom": 5, "larg": 5, "parallel": [5, 10, 16, 17, 19, 20, 24], "files2roug": 5, "giga": 5, "r1": 5, "r2": 5, "rl": 5, "39": 5, "43": 5, "02": [5, 12], "53": 5, "17": [5, 17, 25], "18": 5, "77": 5, "28": [5, 7], "98": [5, 22], "56": 5, "36": 5, "38": 5, "37": 5, "76": 5, "60": 5, "44": 5, "31": 5, "66": [5, 7], "34": 5, "46": 5, "33": [5, 13], "42": 5, "emb": [5, 17], "hid": 5, "40": [5, 22, 23], "90": 5, "91": 5, "99": 5, "25": [5, 13], "59": 5, "97": 5, "93": 5, "67": 5, "1024": 5, "41": [5, 7, 13], "94": 5, "27": 5, "83": 5, "09": 5, "54": 5, "45": 5, "51": 5, "vinyal": [5, 25], "fortunato": 5, "jaitli": 5, "2015": [5, 25], "nip": 5, "liu": [5, 25], "man": [5, 25], "2017": [5, 14, 22, 25], "acl": [5, 14, 25], "cho": [5, 25], "bengio": [5, 25], "2014": [5, 25], "neural": [5, 9, 12, 14, 17, 19, 25], "iclr": [5, 25], "pham": [5, 25], "approach": [5, 11, 12, 13, 17], "emnlp": [5, 25], "preliminari": [6, 8], "wiki_103": 6, "prepare_wikitext": 6, "103_data": 6, "wikitext103": 6, "shuffl": [6, 13, 22], "chmod": [6, 8], "snippet": 6, "40000": 6, "won": 6, "inde": 6, "aggress": 6, "joiner_annot": 6, "preserve_placehold": 6, "case_markup": 6, "soft_case_region": 6, "preserve_segmented_token": 6, "n_symbol": 6, "tokenizer_default": 6, "learner": 6, "bpelearn": 6, "ingest_fil": 6, "raw": [6, 9, 12, 17, 19, 23], "data_fil": 6, "tokenize_fil": 6, "explain": 6, "therefor": 6, "wikitext": 6, "observ": 6, "built": [6, 11, 12, 15, 17], "tansform": 6, "gpt": [6, 15], "unsupervis": 6, "multitask": 6, "block": [6, 19, 23], "mention": [6, 13], "slide": 6, "plai": 6, "role": 6, "model_task": [6, 22], "transformer_lm": [6, 22], "monitor": 6, "perplex": [6, 13, 15], "trigger": [6, 15], "head": [6, 8, 9, 13, 17, 22, 24], "lm_input": 6, "proce": 6, "top": [6, 11, 12, 17, 19, 23], "nucleu": [6, 23], "lowest": [6, 13], "lm_step_1000000": 6, "lm_pred_input": 6, "random_sampling_topp": [6, 19, 23], "pip3": 7, "torchvis": [7, 11], "torchaudio": [7, 12], "highli": 7, "perform": [7, 9, 13, 15, 17, 23], "disabl": [7, 13], "global": [7, 13, 15, 17], "cpp_ext": [7, 15], "cuda_ext": [7, 15], "deprecated_fused_adam": 7, "xentropi": 7, "fast_multihead_attn": 7, "edit": 7, "english": [7, 8, 24], "german": [7, 8, 24], "bash": 7, "prepare_wmt_ende_data": 7, "big": [7, 9], "50k": 7, "rtx": 7, "4090": 7, "build_vocab": [7, 20], "wmt17_end": 7, "variou": [7, 22], "wmt17_en_d": 7, "bpe": [7, 9, 20, 22, 23], "bigwmt17_step_50000": 7, "trg": 7, "sacrebleu": [7, 8], "40k": 7, "45k": 7, "newstest2016": 7, "signatur": 7, "nref": 7, "eff": 7, "verbose_scor": 7, "bp": 7, "hyp_len": 7, "64244": 7, "ref_len": 7, "64379": 7, "65": 7, "000": 7, "64357": 7, "992": 7, "63885": 7, "prepare_wmt_data": 8, "binari": [8, 17], "wmt14_en_d": 8, "commoncrawl": 8, "23": 8, "europarl": 8, "v7": 8, "19": 8, "news_commentari": 8, "commentari": 8, "v11": 8, "wmtend": 8, "silent": [8, 17, 20, 22], "ignor": [8, 17, 20, 22, 23], "skip_empty_level": [8, 16, 20, 22], "corpora": [8, 9, 16, 22], "keep_checkpoint": [8, 22], "50": [8, 13, 22, 23], "average_decai": [8, 15, 22], "0005": 8, "1234": 8, "report_everi": [8, 13, 22], "100000": [8, 12, 22], "4000": [8, 22], "share_decoder_embed": [8, 13, 22], "testset": 8, "spm_encod": 8, "sp": 8, "model_step": [8, 13], "echo": [8, 13], "basenam": 8, "16384": 8, "hyp_": 8, "done": [8, 13, 19], "note1": 8, "often": [8, 20, 22, 23], "note2": 8, "hypothesi": 8, "spm_decod": 8, "input_format": 8, "piec": 8, "prepar": [9, 10, 15, 19], "contributor": 9, "guidelin": 9, "absolut": 9, "alibi": 9, "pretrain": [9, 14, 17, 22], "glove": [9, 22], "ensembl": [9, 23], "special": [9, 10, 20, 22, 23], "purpos": [9, 24], "bart": 9, "switchout": [9, 25], "finetun": 9, "while": [9, 13, 17], "supervis": [9, 17, 22], "server": [9, 22], "ii": 9, "docker": 9, "iii": 9, "wiki": [9, 22], "103": 9, "clean": [9, 13], "summar": [9, 24, 25], "cnn": [9, 12, 13, 15, 22], "dm": 9, "gate": [9, 17, 22], "graph": [9, 17, 22], "quick": 9, "acknowledg": 9, "prefix": [9, 15], "suffix": 9, "token_drop": 9, "token_mask": 9, "uppercas": 9, "onmttok": 9, "reproduc": [9, 13], "prune": 9, "trick": [9, 15, 17], "effici": [9, 15, 25], "framework": [9, 22], "strategi": [9, 16], "loader": 9, "faq": [9, 24], "speech": 9, "embeddings_to_torch": 10, "ylhsieh": 10, "one2": 10, "usag": [10, 20, 21, 22, 23], "emb_file_both": 10, "emb_file_enc": 10, "emb_file_dec": 10, "output_fil": 10, "dict_fil": 10, "skip_lin": 10, "usagecomplet": 10, "info": [10, 16, 22, 23], "onmt_preprocess": [10, 11, 12, 13], "train_src": [10, 11, 12, 13], "train_tgt": [10, 11, 12, 13], "valid_src": [10, 11, 12, 13], "valid_tgt": [10, 11, 12, 13], "pre_word_vecs_enc": [10, 22], "enc": [10, 22], "pre_word_vecs_dec": [10, 22], "dec": [10, 17, 22], "bunch": 10, "tmp": 10, "de2": 10, "max_generator_batch": 10, "model1": 10, "seed1": 10, "model2": 10, "seed2": 10, "train_id": 10, "from_backtransl": 10, "my_data": 10, "dump": [10, 20, 22, 23, 24], "train_a": 10, "train_b": 10, "data_id": 10, "data_weight": 10, "mani": [10, 13, 15, 19, 22], "shard_siz": [10, 11, 12, 13], "train_align": 10, "valid_align": 10, "mask": [10, 17, 20, 22, 23], "deep": [11, 12], "driven": 11, "caption": [11, 13], "optic": 11, "recognit": 11, "latex": [11, 12], "decompil": 11, "formula": 11, "goal": 11, "compil": 11, "frac": 11, "delta": 11, "cdot": 11, "visual": [11, 22, 24], "markup": 11, "technic": [11, 14], "conda": 11, "pillow": 11, "math": 11, "im2text": 11, "tgz": [11, 12], "sea": [11, 12], "harvard": [11, 12], "im2text_smal": 11, "tar": [11, 12, 13, 24], "zxf": [11, 12], "data_typ": [11, 12, 13, 16, 19, 22, 23], "img": 11, "src_dir": [11, 12, 13], "demo": [11, 12, 24], "tgt_words_min_frequ": [11, 22], "500": [11, 13, 22, 24], "image_channel_s": 11, "model_typ": [11, 12, 13, 22], "80": 11, "model_acc_x_ppl_x_e13": [11, 12], "max_length": [11, 13, 19, 23], "im2latex": 11, "100k": 11, "shall": [11, 12], "label0_token0": [11, 12], "label0_token1": [11, 12], "label0_tokenn0": [11, 12], "label1_token0": [11, 12], "label1_token1": [11, 12], "label1_tokenn1": [11, 12], "label2_token0": [11, 12], "label2_token1": [11, 12], "label2_tokenn2": [11, 12], "image0_path": 11, "image1_path": 11, "image2_path": 11, "fourier": 12, "stft": 12, "convolut": [12, 17, 25], "sudo": 12, "apt": 12, "sox": 12, "libsox": 12, "dev": [12, 13], "fmt": 12, "librosa": 12, "an4_dataset": 12, "300": 12, "audio_enc_pool": 12, "0003": 12, "speech0_path": 12, "speech1_path": 12, "speech2_path": 12, "sample_r": 12, "16000": 12, "window_s": 12, "spectrogram": 12, "window_strid": 12, "ham": 12, "deepspeech": 12, "exploit": 13, "tempor": 13, "youtubeclip": 13, "xvf": 13, "decompress": 13, "archiv": 13, "youtube2text": 13, "throw": 13, "awai": 13, "googlenet": 13, "youtube2text_iccv15": 13, "yt2t": 13, "vid": 13, "avi": 13, "pickl": 13, "yt": 13, "ytc": 13, "youtub": 13, "hash": 13, "join": 13, "dict_youtube_map": 13, "pkl": 13, "rb": 13, "yt2vid": 13, "listdir": 13, "hashi": 13, "ext": 13, "splitext": 13, "fpath_old": 13, "f_new": 13, "fpath_new": 13, "low": 13, "framer": 13, "fi": 13, "ffmpeg": 13, "frame": 13, "environ": 13, "variabl": [13, 16, 19], "y2t2": 13, "back": [13, 15], "pwd": 13, "img_feature_extractor": 13, "restrict": [13, 20, 22, 23], "pythonpath": 13, "vid_feature_extractor": 13, "root_dir": 13, "out_dir": 13, "r152": 13, "count": [13, 15, 16, 19, 20, 22, 23], "equal": [13, 19, 22], "1970": 13, "wc": 13, "rerun": 13, "miss": 13, "unexpect": 13, "issu": 13, "associ": 13, "filenam": [13, 22], "skip": [13, 20, 22], "ann": 13, "vid2ann": 13, "vid_nam": 13, "item": [13, 16, 17], "keyerror": 13, "train_fil": 13, "yt2t_train_fil": 13, "val_fil": 13, "yt2t_val_fil": 13, "val_fold": 13, "yt2t_val_folded_fil": 13, "test_fil": 13, "yt2t_test_fil": 13, "train_cap": 13, "yt2t_train_cap": 13, "val_cap": 13, "yt2t_val_cap": 13, "vid_path": 13, "npy": 13, "enumer": 13, "split_nam": 13, "elif": 13, "assert": 13, "small": [13, 24], "0001": 13, "model_step_7200": 13, "7200": 13, "frequenc": [13, 20, 22, 23], "coco": 13, "predict": [13, 19, 22, 23, 24], "fork": 13, "flaut": 13, "url": [13, 14, 25], "pprint": 13, "pycocoevalcap": 13, "meteor": 13, "cider": 13, "spice": 13, "__name__": 13, "__main__": 13, "scorer": [13, 19], "gt": 13, "outp": 13, "vid_id": 13, "all_scor": 13, "compute_scor": 13, "isinst": 13, "sc": 13, "bleu1": 13, "7888553878084233": 13, "bleu2": 13, "6729376621109295": 13, "bleu3": 13, "5778428507344473": 13, "bleu4": 13, "47633625833397897": 13, "7122415518428051": 13, "31829562714082704": 13, "6811305229481235": 13, "044147089472463576": 13, "stack": [13, 17, 22], "against": 13, "row": 13, "tabl": [13, 17, 23], "4028": 13, "2900": 13, "4801": 13, "downsampl": 13, "26": [13, 25], "240": 13, "fp": 13, "resnet": 13, "lowercas": 13, "tvt": 13, "view": 13, "msvd": 13, "yt2t_2": 13, "untar": 13, "subssampl": 13, "reprocess": 13, "2345": 13, "maketran": 13, "whitespac": 13, "train_data": 13, "val_data": 13, "test_data": 13, "datum": 13, "model_step_": 13, "7000": 13, "estim": [13, 15], "epoch": 13, "scale": [13, 15, 17, 19, 22], "accordingli": 13, "earli": [13, 15, 22], "stop": [13, 15, 20, 22, 23], "find_val_stop": 13, "test_early_stop": 13, "process_result": 13, "argpars": [13, 18], "defaultdict": 13, "panda": 13, "pd": 13, "load_result": 13, "fname": 13, "junk": 13, "score_lin": 13, "metric": [13, 15, 22, 23], "score_num": 13, "float": [13, 15, 17, 19], "endswith": 13, "df": 13, "datafram": 13, "find_absolute_stop": 13, "idxmax": 13, "find_early_stop": 13, "stop_count": 13, "count_since_max": 13, "ended_metr": 13, "iterrow": 13, "seri": 13, "find_stop": 13, "argumentpars": 13, "locat": 13, "add_argu": 13, "wors": 13, "parse_arg": 13, "idx": 13, "iteritem": 13, "print": [13, 15, 22, 23], "loc": 13, "touch": 13, "1v": 13, "null": [13, 24], "val_stop": 13, "test_result": 13, "IFS": 13, "awk": 13, "nf": 13, "tee": 13, "cat": 13, "thu": [13, 15], "2000": 13, "took": 13, "522": 13, "testlen": 13, "3410": 13, "reflen": 13, "3417": 13, "guess": 13, "2740": 13, "2070": 13, "1400": 13, "2664": 13, "1562": 13, "887": 13, "386": 13, "9979514193734276": 13, "7796296150773093": 13, "6659837622637965": 13, "5745524496015597": 13, "4779574102543823": 13, "7541600090591118": 13, "3259497476899707": 13, "6800279518634998": 13, "046435637924854": 13, "72": 13, "11": 13, "24m": 13, "perhap": 13, "residu": [13, 17], "altern": [13, 17], "9861": 13, "fewer": 13, "overal": 13, "nearli": 13, "favor": 13, "portal": 14, "packag": [14, 18], "readi": 14, "go": [14, 19, 20, 22, 24], "familiar": 14, "yourself": 14, "research": 14, "guillaum": 14, "klein": 14, "yoon": 14, "kim": 14, "jean": 14, "senellart": 14, "proc": [14, 25], "doi": [14, 25], "18653": 14, "p17": 14, "4012": 14, "gitter": 14, "channel": [14, 17], "basemodel": 15, "encoderbas": [15, 17], "decoderbas": [15, 17], "src_len": [15, 17, 19], "bptt": [15, 22], "with_align": 15, "propag": 15, "longtensor": [15, 17, 19], "tgt_len": [15, 17], "boolean": [15, 19], "init": [15, 17, 22], "floattensor": [15, 17, 19], "nmtmodel": [15, 17], "count_paramet": 15, "callback": 15, "enc_out": [15, 17, 19], "exclud": 15, "initiliaz": 15, "enc_final_h": [15, 17], "languagemodel": 15, "transformerlmdecod": 15, "train_loss": 15, "valid_loss": 15, "scoring_prepar": 15, "train_scor": 15, "valid_scor": 15, "trunc_siz": 15, "norm_method": 15, "sent": [15, 16, 22, 23], "train_eval_step": [15, 22], "report_manag": 15, "model_sav": 15, "average_everi": [15, 22], "fp32": [15, 22, 23], "earlystopp": 15, "util": 15, "losscomputebas": 15, "scoringprepar": 15, "calcul": [15, 17, 19, 22], "training_eval_handl": 15, "accum": [15, 16], "ordin": 15, "rank": [15, 19, 22], "reportmgrbas": 15, "lear": 15, "modelsaverbas": 15, "saver": 15, "earlystop": 15, "mecan": 15, "ff": [15, 17], "dropaout": 15, "schedul": 15, "train_it": 15, "valid_it": 15, "loop": 15, "possibli": [15, 17], "nmt": [15, 19, 22], "moving_averag": [15, 22], "n_batch": 15, "n_sent": 15, "n_word": 15, "n_correct": 15, "computed_metr": 15, "accuraci": [15, 19], "elaps": 15, "static": [15, 22], "all_gather_stat": 15, "max_siz": 15, "accross": 15, "buffer": [15, 22], "all_gather_stats_list": 15, "stat_list": 15, "our_stat": 15, "elapsed_tim": 15, "log_tensorboard": 15, "writer": 15, "patienc": 15, "displai": 15, "num_step": 15, "stdout": 15, "ppl": 15, "update_n_src_word": 15, "sume": 15, "n_src_word": 15, "xent": 15, "cross": [15, 17, 22], "entropi": 15, "losscomput": 15, "criterion": 15, "lambda_coverag": [15, 22], "tgt_shift_index": 15, "lm_gener": 15, "lm_prior_lambda": [15, 22], "lm_prior_tau": [15, 22], "lm_prior_model": [15, 22], "nlloss": 15, "off": [15, 22], "hyper": 15, "param": 15, "scaler": 15, "attn": [15, 17, 19, 23], "trunc_start": 15, "approxim": [15, 22], "reliev": 15, "tupl": [15, 17], "from_opt": [15, 16, 17], "subclass": [15, 17, 19], "wrap": [15, 18], "nllloss": 15, "relev": [15, 17, 19], "learning_rate_decay_fn": 15, "mostli": 15, "thin": 15, "grad": 15, "callabl": [15, 19], "factor": 15, "clip": 15, "properti": [15, 17], "amp": [15, 22], "precis": [15, 23], "backward": 15, "ownership": 15, "emploi": 15, "training_step": 15, "zero_grad": 15, "set_to_non": 15, "zero": [15, 17, 19, 22, 23], "adafactor": [15, 22], "lr": 15, "beta1": [15, 22], "beta2": [15, 22], "999": [15, 22], "eps1": 15, "1e": [15, 17, 22], "eps2": 15, "001": [15, 22], "cliping_threshold": 15, "non_constant_decai": 15, "enable_factor": 15, "ams_grad": 15, "weight_decai": 15, "closur": 15, "reevalu": 15, "unless": 15, "otherwis": [15, 22, 23], "fusedadam": [15, 22], "bias_correct": 15, "ep": [15, 17], "08": 15, "eps_inside_sqrt": 15, "amsgrad": 15, "apex": [15, 22], "coeffici": 15, "squar": 15, "denomin": 15, "l2": 15, "variant": 15, "converg": [15, 24], "NOT": 15, "root": 15, "output_param": 15, "grad_norm": 15, "half": 15, "dynamicdatasetit": 16, "corpora_info": 16, "offset": 16, "iterabledataset": 16, "corpustask": 16, "multipli": 16, "increment": [16, 22], "secur": [16, 20, 22], "encout": [16, 20, 22], "sort_kei": 16, "mixer": 16, "mixingstrategi": 16, "batch_it": 16, "chunk": 16, "initil": 16, "sequentialmix": 16, "exhaust": 16, "weightedmix": 16, "weightedli": 16, "infinit": 16, "parallelcorpusiter": 16, "transformpip": 16, "word_vocab_s": 17, "word_padding_idx": 17, "feat_padding_idx": 17, "feat_vocab_s": 17, "spars": 17, "freeze_word_vec": 17, "abil": 17, "linguist": [17, 25], "sh16": [17, 25], "positionalencod": 17, "feat_dim_expon": 17, "embbed": 17, "emb_lut": 17, "nfeat": 17, "embedding_s": 17, "load_pretrained_vector": 17, "emb_fil": 17, "serial": 17, "word_lut": 17, "dim": 17, "enc_typ": 17, "max_len": 17, "vsp": [17, 25], "seq_len": [17, 19], "nonetyp": [17, 19], "stepwis": 17, "position_ffn": 17, "positionwisefeedforward": [17, 22], "d_model": 17, "d_ff": 17, "activation_fn": 17, "relu": [17, 22], "layer_norm": [17, 22], "ffn": [17, 22], "fnn": 17, "activationfunct": 17, "input_len": 17, "model_dim": 17, "2x": 17, "num_lay": 17, "transformerencod": 17, "pos_ffn_activation_fn": [17, 22], "inner": 17, "rnnencod": 17, "use_bridg": 17, "gru": [17, 22], "sru": [17, 22], "ggnnencod": 17, "autocr": 17, "cnnencod": 17, "cnn_kernel_width": [17, 22], "gag": [17, 25], "meanencod": 17, "trivial": 17, "simpli": [17, 24], "pool": 17, "transformerdecod": 17, "self_attn_typ": [17, 22], "aan_useffn": [17, 22], "transformerdecoderbas": 17, "context_attn": 17, "distanc": [17, 22], "aan": [17, 22], "guid": 17, "tlen": 17, "feat": [17, 18, 20, 22, 23], "slen": 17, "rnndecoderbas": 17, "bidirectional_encod": 17, "attn_typ": 17, "attn_func": 17, "softmax": [17, 22, 23], "coverage_attn": [17, 22], "context_g": [17, 22], "copy_attn_typ": [17, 22], "globalattent": 17, "contextg": 17, "dec_out": 17, "init_st": 17, "stdrnndecod": 17, "fulli": 17, "cudnn": 17, "By": [17, 25], "bcb14": [17, 25], "input_feed": 17, "inputfeedrnndecod": 17, "lpm15": [17, 25], "cnndecod": 17, "convmultistepattent": 17, "enc_hidden": 17, "matrix": [17, 22], "queri": [17, 22], "parameter": 17, "convex": 17, "combin": [17, 23], "construct": 17, "sum_": 17, "seqlength": 17, "a_j": 17, "h_j": 17, "w_a": 17, "v_a": 17, "tanh": 17, "u_a": 17, "sparsemax": [17, 22], "yet": [17, 19], "distribtut": 17, "h_t": 17, "h_": 17, "unnorm": 17, "multiheadedattent": 17, "head_count": 17, "simulatan": 17, "select": [17, 19, 22], "divis": 17, "key_len": 17, "query_len": 17, "averageattent": 17, "acceler": [17, 25], "zxs18": [17, 25], "layer_in": 17, "t_len": 17, "gating_out": 17, "average_out": 17, "input_s": 17, "conv": [17, 22], "oper": [17, 20], "apply_mask": 17, "base_target_emb": 17, "input_from_dec": 17, "encoder_out_top": 17, "encoder_out_combin": 17, "height": 17, "width": 17, "calc": 17, "copygener": 17, "output_s": 17, "pad_idx": 17, "slm17": [17, 25], "p_": 17, "tgt_dict": 17, "z": 17, "probil": 17, "taken": 17, "src_map": [17, 19], "impli": 17, "extra_word": 17, "structured_attent": 17, "matrixtre": 17, "tree": 17, "theorem": 17, "margin": 17, "ll17": [17, 25], "overridden": 17, "recip": 17, "within": [17, 18], "afterward": 17, "former": 17, "care": 17, "regist": 17, "hook": 17, "latter": 17, "translation_serv": 18, "servermodel": 18, "preprocess_opt": 18, "tokenizer_opt": 18, "postprocess_opt": 18, "custom_opt": 18, "features_opt": 18, "processu": 18, "postprocess": 18, "func": [18, 19], "do_timeout": 18, "neg": [18, 22], "build_token": 18, "attr": 18, "on_timemout": 18, "maybe_convert_align": 18, "align_scor": 18, "correspand": 18, "maybe_detoken": 18, "maybe_detokenize_with_align": 18, "seper": 18, "maybe_postprocess": 18, "maybe_preprocess": 18, "maybe_token": 18, "maybe_transform_feat": 18, "raw_src": 18, "tok_src": 18, "inferfeatstransform": 18, "parse_opt": 18, "namespac": 18, "rebuild_seg_packag": 18, "all_preprocess": 18, "rebuild": 18, "segment": [18, 20, 22, 23], "n_seg": 18, "to_gpu": 18, "tokenizer_mark": 18, "marker": 18, "servermodelerror": 18, "timer": 18, "translationserv": 18, "clone_model": 18, "list_model": 18, "load_model": 18, "model_kwarg": 18, "preload_model": 18, "preload": 18, "intern": 18, "datastructur": 18, "lua": 18, "config_fil": 18, "unload_model": 18, "cancel": 18, "src_raw": 19, "pred_sent": 19, "pred_scor": 19, "tgt_sent": 19, "gold_scor": 19, "word_align": 19, "prob": 19, "gold_sent": 19, "sent_numb": 19, "random_sampling_topk": [19, 23], "random_sampling_temp": [19, 23], "dump_beam": [19, 23], "frozenset": 19, "replace_unk": [19, 23], "ban_unk_token": [19, 23], "phrase_t": [19, 23], "report_tim": [19, 23], "global_scor": 19, "report_scor": 19, "logger": 19, "with_scor": [19, 23], "translate_batch": 19, "attn_debug": [19, 23], "translationbuild": 19, "underli": 19, "address": 19, "rare": 19, "lsl": [19, 25], "unknown": 19, "decodestrategi": 19, "parallel_path": 19, "exclusion_token": 19, "return_attent": 19, "magic": 19, "shortest": 19, "begin": 19, "longest": 19, "presum": 19, "cutoff": 19, "forbidden": 19, "hold": 19, "inp_seq_len": 19, "inp": 19, "seq": 19, "alive_seq": 19, "grow": 19, "axi": 19, "is_finish": 19, "bytetensor": 19, "alive_attn": 19, "target_prefix": 19, "prefix_seq_len": 19, "log_prob": 19, "ngram": [19, 23], "thant": 19, "onc": [19, 22], "wai": 19, "put": 19, "lead": 19, "complex": [19, 24], "ingredi": 19, "maybe_update_forbidden_token": 19, "reorder": 19, "forbidden_token": 19, "maybe_update_target_prefix": 19, "select_index": 19, "aliv": 19, "logit": [19, 23], "vocab_s": [19, 22], "update_finish": 19, "attribut": 19, "beamsearch": 19, "beamsearchbas": 19, "greedy_search": 19, "sample_with_temperatur": 19, "sampling_temp": 19, "keep_topk": 19, "keep_topp": 19, "randomli": 19, "categor": 19, "categori": 19, "inf": 19, "logsumexp": 19, "potenti": [19, 24], "chosen": 19, "until": [19, 23], "cumul": [19, 23], "greater": 19, "condit": [19, 22, 23], "topk_id": 19, "topk_scor": 19, "greedysearch": 19, "either": [19, 22], "event": 19, "reach": 19, "gnmtglobalscor": 19, "penaltybuild": 19, "cov_pen": 19, "length_pen": 19, "pen": 19, "cov": 19, "has_cov_pen": 19, "op": 19, "isn": 19, "has_len_pen": 19, "coverage_non": 19, "coverage_summari": 19, "coverage_wu": 19, "gnmt": 19, "wsc": [19, 25], "almost": [19, 22], "length_averag": 19, "cur_len": 19, "length_non": 19, "unmodifi": 19, "length_wu": 19, "save_config": [20, 22, 23], "num_thread": 20, "learn_subword": 20, "learn_subwords_s": 20, "vocab_sample_queue_s": 20, "decoder_start_token": [20, 22], "default_speci": [20, 22], "spacer": [20, 22, 23], "src_subword_vocab": [20, 22, 23], "tgt_subword_vocab": [20, 22, 23], "src_vocab_threshold": [20, 22, 23], "tgt_vocab_threshold": [20, 22, 23], "gpt2_pretok": [20, 22, 23], "scripts_ok": [20, 22, 23], "scripts_nok": [20, 22, 23], "langid": [20, 22, 23], "encount": [20, 22], "rais": [20, 22], "32000": 20, "default_specila": [20, 22], "192": [20, 22, 23], "prepend": [20, 22, 23], "fuzzi": [20, 22, 23], "inlin": [20, 22, 23], "ph_": [20, 22, 23], "_beg": [20, 22, 23], "_end": [20, 22, 23], "_std": [20, 22, 23], "rotat": [20, 22, 23], "percentag": [20, 22, 23], "fraction": [20, 22, 23], "tau": [20, 22, 23], "wpdn18": [20, 22, 23, 25], "smaller": [20, 22, 23], "divers": [20, 22, 23], "unigram": [20, 22, 23], "earlier": [20, 22, 23], "byte": [20, 22, 23], "unicodata": [20, 22, 23], "debug": [21, 22, 23], "dump_transform": [22, 24], "src_words_min_frequ": 22, "freeze_encod": 22, "freeze_decod": 22, "gelu": 22, "silu": 22, "input_fe": 22, "global_attention_funct": 22, "generator_funct": 22, "copy_attn_forc": 22, "loss_scal": 22, "apex_opt_level": 22, "o0": 22, "o1": 22, "o2": 22, "o3": 22, "gpu_backend": 22, "gpu_verbose_level": 22, "keep_stat": 22, "single_pass": 22, "early_stop": 22, "early_stopping_criteria": 22, "adadelta": 22, "sparseadam": 22, "truncated_decod": 22, "adam_beta1": 22, "decay_step": 22, "noamwd": 22, "rsqrt": 22, "log_fil": [22, 23], "log_file_level": [22, 23], "critic": [22, 23], "notset": [22, 23], "train_metr": 22, "valid_metr": 22, "scoring_debug": 22, "dump_pr": 22, "exp_host": 22, "tensorboard_log_dir": 22, "override_opt": 22, "disk": 22, "32768": 22, "discard": 22, "sin": 22, "mark": 22, "interleav": 22, "feat_merge_s": 22, "experiment": 22, "kernel_s": 22, "dict_kei": 22, "autogener": 22, "dotprod": 22, "encodingw": 22, "embeddingsmor": 22, "09864set": 22, "usemaximum": 22, "pdf": 22, "mhanot": 22, "proj": 22, "garg": 22, "2019": 22, "1909": 22, "02074": 22, "leav": 22, "lambda_prior_lambda": 22, "lambda_prior_tau": 22, "opt_level": 22, "io": 22, "_n": 22, "backend": 22, "nccl": 22, "localhost": 22, "2106": 22, "09685": 22, "successfulli": 22, "thumb": 22, "uniform": 22, "xavier_uniform": 22, "state_dict": 22, "resett": 22, "readm": 22, "criteria": 22, "mirror": 22, "initial_accumulator_valu": 22, "literatur": 22, "seemingli": 22, "discourag": 22, "consider": 22, "adopt": 22, "kera": 22, "www": 22, "api_doc": 22, "tf": 22, "adamoptim": 22, "recent": 22, "epsilon": 22, "1512": 22, "00567": 22, "marian": 22, "aclweb": 22, "anthologi": 22, "p18": 22, "4020": 22, "exponenti": 22, "wikipedia": 22, "update_learning_r": 22, "gone": 22, "warmup": 22, "under": [22, 23], "crayon": 22, "pick": 22, "awith": 22, "mini": 22, "refil": 22, "int8": 23, "avg_raw_prob": 23, "align_debug": 23, "dtypefp32": 23, "gtx1080int8": 23, "nativ": 23, "whose": [23, 24], "learnt": 23, "1904": 23, "09751": 23, "minimum": 23, "250": 23, "repetit": 23, "had": 23, "highest": 23, "proba": 23, "upgrad": 24, "tuto": 24, "yasmin": 24, "moslem": 24, "10k": 24, "s3": 24, "amazonaw": 24, "trainingdata": 24, "gz": 24, "xf": 24, "5k": 24, "nation": 24, "bureaucraci": 24, "parliament": 24, "apo": 24, "legisl": 24, "prerog": 24, "void": 24, "provis": 24, "extent": 24, "laid": 24, "feder": 24, "senior": 24, "instructor": 24, "italian": 24, "fit": 24, "postur": 24, "gym": 24, "stretch": 24, "pilat": 24, "2004": 24, "collabor": 24, "antich": 24, "person": 24, "toy_en_d": 24, "simplest": 24, "dump_field": 24, "simplifi": 24, "inspect": 24, "advand": 24, "model_step_1000": 24, "pred_1000": 24, "terribl": 24, "million": 24, "dzmitri": 25, "kyunghyun": 25, "yoshua": 25, "1409": 25, "0473": 25, "0473v3": 25, "1146": 25, "annurev": 25, "neuro": 25, "041002": 25, "131047": 25, "jona": 25, "gehr": 25, "michael": 25, "auli": 25, "david": 25, "grangier": 25, "deni": 25, "yarat": 25, "yann": 25, "dauphin": 25, "1705": 25, "03122": 25, "yang": 25, "mirella": 25, "lapata": 25, "09207": 25, "minh": 25, "thang": 25, "hieu": 25, "christoph": 25, "ffectiv": 25, "pproach": 25, "ttention": 25, "eural": 25, "achin": 25, "ranslat": 25, "ilya": 25, "sutskev": 25, "quoc": 25, "le": 25, "oriol": 25, "wojciech": 25, "zaremba": 25, "ddress": 25, "ord": 25, "roblem": 25, "abigail": 25, "peter": 25, "1704": 25, "04368": 25, "rico": 25, "sennrich": 25, "barri": 25, "haddow": 25, "preprint": 25, "1606": 25, "02892": 25, "2016": 25, "ashish": 25, "vaswani": 25, "shazeer": 25, "niki": 25, "parmar": 25, "jakob": 25, "uszkoreit": 25, "llion": 25, "jone": 25, "aidan": 25, "gomez": 25, "lukasz": 25, "kaiser": 25, "illia": 25, "polosukhin": 25, "1706": 25, "03762": 25, "xinyi": 25, "wang": 25, "zihang": 25, "graham": 25, "neubig": 25, "1808": 25, "07512": 25, "yonghui": 25, "mike": 25, "schuster": 25, "zhifeng": 25, "chen": 25, "mohammad": 25, "norouzi": 25, "wolfgang": 25, "macherei": 25, "krikun": 25, "yuan": 25, "cao": 25, "qin": 25, "gao": 25, "klau": 25, "gap": 25, "human": 25, "1609": 25, "08144": 25, "biao": 25, "zhang": 25, "deyi": 25, "xiong": 25, "jinsong": 25, "su": 25, "1805": 25, "00631": 25}, "objects": {"onmt": [[15, 0, 1, "", "Trainer"]], "onmt.Trainer": [[15, 1, 1, "", "train"], [15, 1, 1, "", "validate"]], "onmt.decoders": [[17, 0, 1, "", "CNNDecoder"], [17, 0, 1, "", "DecoderBase"], [17, 0, 1, "", "InputFeedRNNDecoder"], [17, 0, 1, "", "StdRNNDecoder"], [17, 0, 1, "", "TransformerDecoder"]], "onmt.decoders.CNNDecoder": [[17, 1, 1, "", "forward"], [17, 1, 1, "", "from_opt"], [17, 1, 1, "", "init_state"]], "onmt.decoders.DecoderBase": [[17, 1, 1, "", "from_opt"]], "onmt.decoders.TransformerDecoder": [[17, 1, 1, "", "forward"]], "onmt.decoders.decoder": [[17, 0, 1, "", "RNNDecoderBase"]], "onmt.decoders.decoder.RNNDecoderBase": [[17, 1, 1, "", "forward"], [17, 1, 1, "", "from_opt"], [17, 1, 1, "", "init_state"]], "onmt.encoders": [[17, 0, 1, "", "CNNEncoder"], [17, 0, 1, "", "EncoderBase"], [17, 0, 1, "", "GGNNEncoder"], [17, 0, 1, "", "MeanEncoder"], [17, 0, 1, "", "RNNEncoder"], [17, 0, 1, "", "TransformerEncoder"]], "onmt.encoders.CNNEncoder": [[17, 1, 1, "", "forward"], [17, 1, 1, "", "from_opt"]], "onmt.encoders.EncoderBase": [[17, 1, 1, "", "forward"]], "onmt.encoders.GGNNEncoder": [[17, 1, 1, "", "forward"], [17, 1, 1, "", "from_opt"]], "onmt.encoders.MeanEncoder": [[17, 1, 1, "", "forward"], [17, 1, 1, "", "from_opt"]], "onmt.encoders.RNNEncoder": [[17, 1, 1, "", "forward"], [17, 1, 1, "", "from_opt"]], "onmt.encoders.TransformerEncoder": [[17, 1, 1, "", "forward"], [17, 1, 1, "", "from_opt"]], "onmt.inputters": [[16, 0, 1, "", "DynamicDatasetIter"], [16, 0, 1, "", "MixingStrategy"], [16, 0, 1, "", "ParallelCorpus"], [16, 0, 1, "", "ParallelCorpusIterator"], [16, 0, 1, "", "SequentialMixer"], [16, 0, 1, "", "WeightedMixer"]], "onmt.inputters.DynamicDatasetIter": [[16, 1, 1, "", "batch_iter"], [16, 1, 1, "", "from_opt"]], "onmt.inputters.ParallelCorpus": [[16, 1, 1, "", "load"]], "onmt.models": [[15, 0, 1, "", "BaseModel"], [15, 0, 1, "", "LanguageModel"], [15, 0, 1, "", "NMTModel"]], "onmt.models.BaseModel": [[15, 1, 1, "", "forward"]], "onmt.models.LanguageModel": [[15, 1, 1, "", "count_parameters"], [15, 1, 1, "", "forward"]], "onmt.models.NMTModel": [[15, 1, 1, "", "count_parameters"], [15, 1, 1, "", "forward"]], "onmt.modules": [[17, 0, 1, "", "AverageAttention"], [17, 0, 1, "", "ConvMultiStepAttention"], [17, 0, 1, "", "CopyGenerator"], [17, 0, 1, "", "Embeddings"], [17, 0, 1, "", "GlobalAttention"], [17, 0, 1, "", "MultiHeadedAttention"], [17, 0, 1, "", "PositionalEncoding"]], "onmt.modules.AverageAttention": [[17, 1, 1, "", "forward"]], "onmt.modules.ConvMultiStepAttention": [[17, 1, 1, "", "apply_mask"], [17, 1, 1, "", "forward"]], "onmt.modules.CopyGenerator": [[17, 1, 1, "", "forward"]], "onmt.modules.Embeddings": [[17, 2, 1, "", "emb_luts"], [17, 1, 1, "", "forward"], [17, 1, 1, "", "load_pretrained_vectors"], [17, 2, 1, "", "word_lut"]], "onmt.modules.GlobalAttention": [[17, 1, 1, "", "forward"], [17, 1, 1, "", "score"]], "onmt.modules.MultiHeadedAttention": [[17, 1, 1, "", "forward"]], "onmt.modules.PositionalEncoding": [[17, 1, 1, "", "forward"]], "onmt.modules.position_ffn": [[17, 0, 1, "", "PositionwiseFeedForward"]], "onmt.modules.position_ffn.PositionwiseFeedForward": [[17, 1, 1, "", "forward"]], "onmt.modules.structured_attention": [[17, 0, 1, "", "MatrixTree"]], "onmt.modules.structured_attention.MatrixTree": [[17, 1, 1, "", "forward"]], "onmt.translate": [[19, 0, 1, "", "BeamSearch"], [19, 0, 1, "", "DecodeStrategy"], [19, 0, 1, "", "GNMTGlobalScorer"], [19, 0, 1, "", "GreedySearch"], [19, 0, 1, "", "Translation"], [19, 0, 1, "", "TranslationBuilder"], [19, 0, 1, "", "Translator"]], "onmt.translate.BeamSearch": [[19, 1, 1, "", "initialize"]], "onmt.translate.DecodeStrategy": [[19, 1, 1, "", "advance"], [19, 1, 1, "", "block_ngram_repeats"], [19, 1, 1, "", "initialize"], [19, 1, 1, "", "maybe_update_forbidden_tokens"], [19, 1, 1, "", "maybe_update_target_prefix"], [19, 1, 1, "", "target_prefixing"], [19, 1, 1, "", "update_finished"]], "onmt.translate.GreedySearch": [[19, 1, 1, "", "advance"], [19, 1, 1, "", "initialize"], [19, 1, 1, "", "update_finished"]], "onmt.translate.Translation": [[19, 1, 1, "", "log"]], "onmt.translate.Translator": [[19, 1, 1, "", "translate_batch"]], "onmt.translate.greedy_search": [[19, 3, 1, "", "sample_with_temperature"]], "onmt.translate.penalties": [[19, 0, 1, "", "PenaltyBuilder"]], "onmt.translate.penalties.PenaltyBuilder": [[19, 1, 1, "", "coverage_none"], [19, 1, 1, "", "coverage_summary"], [19, 1, 1, "", "coverage_wu"], [19, 1, 1, "", "length_average"], [19, 1, 1, "", "length_none"], [19, 1, 1, "", "length_wu"]], "onmt.translate.translation_server": [[18, 0, 1, "", "ServerModel"], [18, 4, 1, "", "ServerModelError"], [18, 0, 1, "", "Timer"], [18, 0, 1, "", "TranslationServer"]], "onmt.translate.translation_server.ServerModel": [[18, 1, 1, "", "build_tokenizer"], [18, 1, 1, "", "detokenize"], [18, 1, 1, "", "do_timeout"], [18, 1, 1, "", "maybe_convert_align"], [18, 1, 1, "", "maybe_detokenize"], [18, 1, 1, "", "maybe_detokenize_with_align"], [18, 1, 1, "", "maybe_postprocess"], [18, 1, 1, "", "maybe_preprocess"], [18, 1, 1, "", "maybe_tokenize"], [18, 1, 1, "", "maybe_transform_feats"], [18, 1, 1, "", "parse_opt"], [18, 1, 1, "", "postprocess"], [18, 1, 1, "", "preprocess"], [18, 1, 1, "", "rebuild_seg_packages"], [18, 1, 1, "", "to_gpu"], [18, 1, 1, "", "tokenize"], [18, 1, 1, "", "tokenizer_marker"]], "onmt.translate.translation_server.TranslationServer": [[18, 1, 1, "", "clone_model"], [18, 1, 1, "", "list_models"], [18, 1, 1, "", "load_model"], [18, 1, 1, "", "preload_model"], [18, 1, 1, "", "run"], [18, 1, 1, "", "start"], [18, 1, 1, "", "unload_model"]], "onmt.utils": [[15, 0, 1, "", "AdaFactor"], [15, 0, 1, "", "FusedAdam"], [15, 0, 1, "", "Optimizer"], [15, 0, 1, "", "Statistics"]], "onmt.utils.AdaFactor": [[15, 1, 1, "", "step"]], "onmt.utils.FusedAdam": [[15, 1, 1, "", "step"]], "onmt.utils.Optimizer": [[15, 2, 1, "", "amp"], [15, 1, 1, "", "backward"], [15, 1, 1, "", "from_opt"], [15, 1, 1, "", "learning_rate"], [15, 1, 1, "", "step"], [15, 2, 1, "", "training_step"], [15, 1, 1, "", "zero_grad"]], "onmt.utils.Statistics": [[15, 1, 1, "", "accuracy"], [15, 1, 1, "", "all_gather_stats"], [15, 1, 1, "", "all_gather_stats_list"], [15, 1, 1, "", "elapsed_time"], [15, 1, 1, "", "log_tensorboard"], [15, 1, 1, "", "output"], [15, 1, 1, "", "ppl"], [15, 1, 1, "", "update"], [15, 1, 1, "", "xent"]], "onmt.utils.loss": [[15, 0, 1, "", "LossCompute"]], "onmt.utils.loss.LossCompute": [[15, 1, 1, "", "forward"], [15, 1, 1, "", "from_opts"]]}, "objtypes": {"0": "py:class", "1": "py:method", "2": "py:property", "3": "py:function", "4": "py:exception"}, "objnames": {"0": ["py", "class", "Python class"], "1": ["py", "method", "Python method"], "2": ["py", "property", "Python property"], "3": ["py", "function", "Python function"], "4": ["py", "exception", "Python exception"]}, "titleterms": {"contributor": 0, "guidelin": 0, "docstr": 0, "how": [1, 10], "do": [1, 10], "i": [1, 10], "us": [1, 10], "my": 1, "v2": 1, "model": [1, 5, 6, 8, 10, 15, 18, 22, 23, 24], "v3": 1, "train": [1, 5, 6, 7, 8, 10, 22, 24], "transform": [1, 10, 13, 20, 22, 23], "perform": [1, 2], "tip": [1, 2], "posit": 1, "encod": [1, 17, 22], "absolut": 1, "v": 1, "rel": 1, "rotari": 1, "embed": [1, 10, 17, 22], "alibi": 1, "you": [1, 10], "support": [1, 10], "multi": [1, 10], "gpu": [1, 10], "pretrain": [1, 10], "e": [1, 10], "g": [1, 10], "glove": [1, 10], "exampl": [1, 4, 9, 10], "can": [1, 10], "ensembl": [1, 10], "infer": [1, 4, 5, 10], "weight": [1, 10], "differ": [1, 10], "corpora": [1, 10], "what": 1, "special": 1, "token": 1, "doe": 1, "opennmt": [1, 7, 24], "py": [1, 4, 7, 24], "appli": 1, "fly": 1, "subword": [1, 6, 7, 8, 20, 22, 23], "regular": 1, "when": 1, "ar": 1, "readili": 1, "avail": 1, "data": [1, 3, 4, 5, 6, 7, 8, 16, 20, 22, 23, 24], "gener": [1, 6, 22], "purpos": 1, "filter": [1, 20, 22, 23], "length": 1, "add": 1, "custom": 1, "prefix": [1, 20, 22, 23], "suffix": [1, 20, 22, 23], "convert": 1, "uppercas": [1, 20, 22, 23], "normal": [1, 20, 22, 23], "punctuat": 1, "clean": [1, 6, 20, 22, 23], "dataset": [1, 4, 16], "context": 1, "doc": 1, "awar": 1, "augment": 1, "sourc": 1, "segment": 1, "fuzzi": 1, "match": 1, "neural": [1, 3], "repair": 1, "target": 1, "inlin": 1, "tag": 1, "sentencepiec": 1, "bpe": [1, 6], "nmt": [1, 7], "bart": [1, 20, 22, 23], "style": 1, "nois": 1, "switchout": [1, 20, 22, 23], "sampl": [1, 23], "drop": 1, "some": 1, "mask": 1, "creat": 1, "lora": 1, "8bit": 1, "load": 1, "finetun": [1, 4], "big": 1, "get": [1, 7, 9, 10], "word": [1, 10], "align": [1, 10, 22], "while": [1, 10], "translat": [1, 4, 7, 8, 10, 19, 23, 24], "raw": [1, 10], "from": [1, 10], "averag": [1, 10], "attent": [1, 10, 17, 22], "head": [1, 10], "supervis": [1, 4, 10], "learn": [1, 10], "specif": [1, 6, 10], "updat": 1, "checkpoint": [1, 4], "": 1, "vocabulari": [1, 3, 4, 6, 8], "featur": [1, 20, 22, 23], "set": 1, "up": 1, "server": [1, 18, 21], "work": 1, "configur": [1, 20, 22, 23], "ii": 1, "start": [1, 3, 9, 11, 12], "without": 1, "docker": 1, "0": [1, 6, 8, 24], "code": 1, "1": [1, 6, 8, 24], "instal": [1, 14, 24], "flask": 1, "2": [1, 6, 8, 24], "put": 1, "3": [1, 6, 8, 24], "iii": 1, "iv": 1, "api": [1, 9], "hostnam": 1, "list": 1, "version": [2, 10], "break": 2, "chang": 2, "gate": 3, "graph": 3, "network": 3, "depend": [3, 7, 11, 12], "quick": [3, 11, 12], "format": 3, "note": 3, "option": [3, 11, 12], "acknowledg": [3, 12], "llama": 4, "7b": 4, "replic": 4, "vicuna": 4, "concaten": 4, "input": 4, "ctranslat": 4, "summar": 5, "cnn": 5, "dm": 5, "prepar": [5, 6, 7, 8, 24], "vocab": [5, 20, 22], "evalu": [5, 8], "gigaword": 5, "score": [5, 19], "refer": [5, 25], "languag": 6, "wiki": 6, "103": 6, "step": [6, 8, 24], "download": [6, 8], "pyonmttok": 6, "build": [6, 8, 20], "command": 6, "4": 6, "output": 6, "wmt17": 7, "en": 7, "de": 7, "pytorch": 7, "apex": 7, "run": 7, "content": 9, "frequent": 9, "ask": 9, "question": 9, "script": 9, "legaci": [9, 10], "faq": 10, "preprocess": 10, "imag": 11, "text": [11, 12, 13], "speech": 12, "video": 13, "recurr": 13, "overview": 14, "citat": 14, "addit": 14, "resourc": 14, "framework": 15, "trainer": 15, "loss": 15, "optim": [15, 22], "loader": 16, "iter": 16, "modul": 17, "decod": [17, 19, 22, 23], "core": 18, "class": 19, "strategi": 19, "fuzzymatch": [20, 22, 23], "inferfeat": [20, 22, 23], "inlinetag": [20, 22, 23], "docifi": [20, 22, 23], "token_drop": [20, 22, 23], "token_mask": [20, 22, 23], "common": [20, 22, 23], "onmttok": [20, 22, 23], "reproduc": [20, 22, 23], "name": 21, "argument": 21, "prune": 22, "task": 22, "initi": 22, "type": 22, "rate": 22, "log": [22, 23], "dynam": 22, "beam": 23, "search": 23, "random": 23, "penalti": 23, "trick": 23, "effici": 23, "quickstart": 24}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.viewcode": 1, "sphinxcontrib.bibtex": 9, "sphinx": 57}, "alltitles": {"Contributors": [[0, "contributors"]], "Guidelines": [[0, "guidelines"]], "Docstrings": [[0, "docstrings"]], "How do I use my v2 models in v3 ?": [[1, "how-do-i-use-my-v2-models-in-v3"]], "How do I train the Transformer model?": [[1, "how-do-i-train-the-transformer-model"]], "Performance tips": [[1, "performance-tips"], [2, "performance-tips"]], "Position encoding: Absolute vs Relative vs Rotary Embeddings vs Alibi": [[1, "position-encoding-absolute-vs-relative-vs-rotary-embeddings-vs-alibi"]], "Do you support multi-gpu?": [[1, "do-you-support-multi-gpu"], [10, "do-you-support-multi-gpu"]], "How do I use Pretrained embeddings (e.g. GloVe)?": [[1, "how-do-i-use-pretrained-embeddings-e-g-glove"], [10, "how-do-i-use-pretrained-embeddings-e-g-glove"]], "Example": [[1, "example"], [1, "id1"], [1, "id2"], [1, "id3"], [10, "example"]], "How can I ensemble Models at inference?": [[1, "how-can-i-ensemble-models-at-inference"], [10, "how-can-i-ensemble-models-at-inference"]], "How can I weight different corpora at training?": [[1, "how-can-i-weight-different-corpora-at-training"], [10, "how-can-i-weight-different-corpora-at-training"]], "What special tokens does OpenNMT-py use?": [[1, "what-special-tokens-does-opennmt-py-use"]], "How can I apply on-the-fly tokenization and subword regularization when training?": [[1, "how-can-i-apply-on-the-fly-tokenization-and-subword-regularization-when-training"]], "What are the readily available on-the-fly data transforms?": [[1, "what-are-the-readily-available-on-the-fly-data-transforms"]], "General purpose": [[1, "general-purpose"]], "Filter examples by length": [[1, "filter-examples-by-length"]], "Add custom prefix to examples": [[1, "add-custom-prefix-to-examples"]], "Add custom suffix to examples": [[1, "add-custom-suffix-to-examples"]], "Convert examples to uppercase": [[1, "convert-examples-to-uppercase"]], "Normalize punctuation": [[1, "normalize-punctuation"]], "Clean dataset": [[1, "clean-dataset"]], "Context / Doc aware transform": [[1, "context-doc-aware-transform"]], "Augment source segments with fuzzy matches for Neural Fuzzy Repair": [[1, "augment-source-segments-with-fuzzy-matches-for-neural-fuzzy-repair"]], "Augment source and target segments with inline tags": [[1, "augment-source-and-target-segments-with-inline-tags"]], "Tokenization": [[1, "tokenization"]], "OpenNMT Tokenizer": [[1, "opennmt-tokenizer"]], "SentencePiece": [[1, "sentencepiece"]], "BPE subword-nmt": [[1, "bpe-subword-nmt"]], "BART-style noise": [[1, "bart-style-noise"]], "SwitchOut and sampling": [[1, "switchout-and-sampling"]], "SwitchOut": [[1, "switchout"]], "Drop some tokens": [[1, "drop-some-tokens"]], "Mask some tokens": [[1, "mask-some-tokens"]], "How can I create custom on-the-fly data transforms?": [[1, "how-can-i-create-custom-on-the-fly-data-transforms"]], "How to use LoRa and 8bit loading to finetune a big model ?": [[1, "how-to-use-lora-and-8bit-loading-to-finetune-a-big-model"]], "Can I get word alignments while translating?": [[1, "can-i-get-word-alignments-while-translating"]], "Raw alignments from averaging Transformer attention heads": [[1, "raw-alignments-from-averaging-transformer-attention-heads"], [10, "raw-alignments-from-averaging-transformer-attention-heads"]], "Supervised learning on a specific head": [[1, "supervised-learning-on-a-specific-head"], [10, "supervised-learning-on-a-specific-head"]], "How can I update a checkpoint\u2019s vocabulary?": [[1, "how-can-i-update-a-checkpoint-s-vocabulary"]], "How can I use source word features?": [[1, "how-can-i-use-source-word-features"]], "How can I set up a translation server ?": [[1, "how-can-i-set-up-a-translation-server"]], "I. How it works?": [[1, "i-how-it-works"]], "Configuration:": [[1, "configuration"]], "II. How to start the server without Docker ?": [[1, "ii-how-to-start-the-server-without-docker"]], "0. Get the code": [[1, "get-the-code"]], "1. Install flask": [[1, "install-flask"]], "2. Put some models": [[1, "put-some-models"]], "3. Start the server": [[1, "start-the-server"]], "III. How to start the server with Docker ?": [[1, "iii-how-to-start-the-server-with-docker"]], "IV. How to use the API ?": [[1, "iv-how-to-use-the-api"]], "0. Set the hostname": [[1, "set-the-hostname"]], "1. List models": [[1, "list-models"]], "2. Translate": [[1, "translate"]], "Versions": [[2, "versions"]], "Breaking changes": [[2, "breaking-changes"]], "Gated Graph Neural Networks": [[3, "gated-graph-neural-networks"]], "Dependencies": [[3, "dependencies"], [7, "dependencies"], [11, "dependencies"], [12, "dependencies"]], "Quick Start": [[3, "quick-start"], [11, "quick-start"], [12, "quick-start"]], "Graph data format": [[3, "graph-data-format"]], "Vocabulary notes": [[3, "vocabulary-notes"]], "Options": [[3, "options"], [11, "options"], [12, "options"]], "Acknowledgement": [[3, "acknowledgement"], [12, "acknowledgement"]], "Supervised Finetuning of llama 7B to replicate Vicuna": [[4, "supervised-finetuning-of-llama-7b-to-replicate-vicuna"]], "Data": [[4, "data"], [20, "Data"], [22, "Data"], [23, "Data"]], "Checkpoints": [[4, "checkpoints"]], "Vocabulary": [[4, "vocabulary"]], "Datasets": [[4, "datasets"]], "Finetuning": [[4, "finetuning"]], "Inference": [[4, "inference"], [5, "inference"]], "Concatenation of the checkpoints": [[4, "concatenation-of-the-checkpoints"]], "Input examples": [[4, "input-examples"]], "Inference with translate.py": [[4, "inference-with-translate-py"]], "Inference with CTranslate": [[4, "inference-with-ctranslate"]], "Summarization CNN/DM": [[5, "summarization-cnn-dm"]], "Preparing the data and vocab": [[5, "preparing-the-data-and-vocab"]], "Training": [[5, "training"], [10, "training"]], "Evaluation": [[5, "evaluation"]], "CNN-DM": [[5, "cnn-dm"], [5, "id1"]], "Gigaword": [[5, "gigaword"], [5, "id2"]], "Scores and Models": [[5, "scores-and-models"]], "References": [[5, "references"], [25, "references"]], "Language Model Wiki-103": [[6, "language-model-wiki-103"]], "Step 0: Download and clean the data": [[6, "step-0-download-and-clean-the-data"]], "Step 1: Prepare the subword model - BPE with pyonmttok": [[6, "step-1-prepare-the-subword-model-bpe-with-pyonmttok"]], "Step 2: Build the vocabulary": [[6, "step-2-build-the-vocabulary"]], "Language Model specificities": [[6, "language-model-specificities"]], "BPE specificities": [[6, "bpe-specificities"]], "Build vocabulary command": [[6, "build-vocabulary-command"]], "Step 3: Train the model": [[6, "step-3-train-the-model"]], "Step 4: Generate output": [[6, "step-4-generate-output"]], "Translation WMT17 en-de": [[7, "translation-wmt17-en-de"]], "PyTorch": [[7, "pytorch"]], "Apex": [[7, "apex"]], "Subword-NMT": [[7, "subword-nmt"]], "OpenNMT-py": [[7, "opennmt-py"]], "Running WMT17 EN-DE": [[7, "running-wmt17-en-de"]], "Get Data and prepare": [[7, "get-data-and-prepare"]], "Train": [[7, "train"], [22, "train"]], "Translation": [[8, "translation"], [19, "translation"]], "Step 0: Download the data and prepare the subwords model": [[8, "step-0-download-the-data-and-prepare-the-subwords-model"]], "Step 1. Build the vocabulary.": [[8, "step-1-build-the-vocabulary"]], "Step 2: Train the model": [[8, "step-2-train-the-model"], [24, "step-2-train-the-model"]], "Step 3: Translate and evaluate": [[8, "step-3-translate-and-evaluate"]], "Contents": [[9, "contents"]], "Getting Started": [[9, null]], "Frequently Asked Questions": [[9, null]], "Examples": [[9, null]], "Scripts": [[9, null]], "API": [[9, null]], "Legacy": [[9, null]], "FAQ (Legacy version)": [[10, "faq-legacy-version"]], "How do I use the Transformer model?": [[10, "how-do-i-use-the-transformer-model"]], "Preprocessing": [[10, "preprocessing"]], "Can I get word alignment while translating?": [[10, "can-i-get-word-alignment-while-translating"]], "Image to Text": [[11, "image-to-text"]], "Speech to Text": [[12, "speech-to-text"]], "Video to Text": [[13, "video-to-text"]], "Recurrent": [[13, "recurrent"]], "Transformer": [[13, "transformer"]], "Overview": [[14, "overview"]], "Installation": [[14, "installation"]], "Citation": [[14, "citation"]], "Additional resources": [[14, "additional-resources"]], "Framework": [[15, "framework"]], "Model": [[15, "model"], [23, "Model"]], "Trainer": [[15, "trainer"]], "Loss": [[15, "loss"]], "Optimizer": [[15, "optimizer"]], "Data Loaders": [[16, "data-loaders"]], "Data Iterator": [[16, "data-iterator"]], "Dataset": [[16, "dataset"]], "Modules": [[17, "modules"]], "Embeddings": [[17, "embeddings"], [22, "Embeddings"]], "Encoders": [[17, "encoders"]], "Decoders": [[17, "decoders"]], "Attention": [[17, "attention"]], "Server": [[18, "server"], [21, "server"]], "Models": [[18, "models"]], "Core Server": [[18, "core-server"]], "Translations": [[19, "translations"]], "Translator Class": [[19, "translator-class"]], "Decoding Strategies": [[19, "decoding-strategies"]], "Scoring": [[19, "scoring"]], "Build Vocab": [[20, "build-vocab"]], "Configuration": [[20, "Configuration"], [22, "Configuration"], [23, "Configuration"]], "Vocab": [[20, "Vocab"], [22, "Vocab"]], "Features": [[20, "Features"], [22, "Features"], [23, "Features"]], "Transform/Filter": [[20, "Transform/Filter"], [22, "Transform/Filter"], [23, "Transform/Filter"]], "Transform/Prefix": [[20, "Transform/Prefix"], [22, "Transform/Prefix"], [23, "Transform/Prefix"]], "Transform/Suffix": [[20, "Transform/Suffix"], [22, "Transform/Suffix"], [23, "Transform/Suffix"]], "Transform/FuzzyMatching": [[20, "Transform/FuzzyMatching"], [22, "Transform/FuzzyMatching"], [23, "Transform/FuzzyMatching"]], "Transform/InferFeats": [[20, "Transform/InferFeats"], [22, "Transform/InferFeats"], [23, "Transform/InferFeats"]], "Transform/InlineTags": [[20, "Transform/InlineTags"], [22, "Transform/InlineTags"], [23, "Transform/InlineTags"]], "Transform/Normalize": [[20, "Transform/Normalize"], [22, "Transform/Normalize"], [23, "Transform/Normalize"]], "Transform/BART": [[20, "Transform/BART"], [22, "Transform/BART"], [23, "Transform/BART"]], "Transform/Docify": [[20, "Transform/Docify"], [22, "Transform/Docify"], [23, "Transform/Docify"]], "Transform/SwitchOut": [[20, "Transform/SwitchOut"], [22, "Transform/SwitchOut"], [23, "Transform/SwitchOut"]], "Transform/Token_Drop": [[20, "Transform/Token_Drop"], [22, "Transform/Token_Drop"], [23, "Transform/Token_Drop"]], "Transform/Token_Mask": [[20, "Transform/Token_Mask"], [22, "Transform/Token_Mask"], [23, "Transform/Token_Mask"]], "Transform/Uppercase": [[20, "Transform/Uppercase"], [22, "Transform/Uppercase"], [23, "Transform/Uppercase"]], "Transform/Subword/Common": [[20, "Transform/Subword/Common"], [22, "Transform/Subword/Common"], [23, "Transform/Subword/Common"]], "Transform/Subword/ONMTTOK": [[20, "Transform/Subword/ONMTTOK"], [22, "Transform/Subword/ONMTTOK"], [23, "Transform/Subword/ONMTTOK"]], "Transform/Clean": [[20, "Transform/Clean"], [22, "Transform/Clean"], [23, "Transform/Clean"]], "Reproducibility": [[20, "Reproducibility"], [22, "Reproducibility"], [23, "Reproducibility"]], "Named Arguments": [[21, "Named Arguments"]], "Pruning": [[22, "Pruning"]], "Model-Embeddings": [[22, "Model-Embeddings"]], "Model-Embedding Features": [[22, "Model-Embedding Features"]], "Model- Task": [[22, "Model- Task"]], "Model- Encoder-Decoder": [[22, "Model- Encoder-Decoder"]], "Model- Attention": [[22, "Model- Attention"]], "Model - Alignement": [[22, "Model - Alignement"]], "Generator": [[22, "Generator"]], "General": [[22, "General"]], "Initialization": [[22, "Initialization"]], "Optimization- Type": [[22, "Optimization- Type"]], "Optimization- Rate": [[22, "Optimization- Rate"]], "Logging": [[22, "Logging"], [23, "Logging"]], "Dynamic data": [[22, "Dynamic data"]], "Translate": [[23, "translate"]], "Beam Search": [[23, "Beam Search"]], "Random Sampling": [[23, "Random Sampling"]], "Penalties": [[23, "Penalties"]], "Decoding tricks": [[23, "Decoding tricks"]], "Efficiency": [[23, "Efficiency"]], "Quickstart": [[24, "quickstart"]], "Step 0: Install OpenNMT-py": [[24, "step-0-install-opennmt-py"]], "Step 1: Prepare the data": [[24, "step-1-prepare-the-data"]], "Step 3: Translate": [[24, "step-3-translate"]]}, "indexentries": {"adafactor (class in onmt.utils)": [[15, "onmt.utils.AdaFactor"]], "basemodel (class in onmt.models)": [[15, "onmt.models.BaseModel"]], "fusedadam (class in onmt.utils)": [[15, "onmt.utils.FusedAdam"]], "languagemodel (class in onmt.models)": [[15, "onmt.models.LanguageModel"]], "losscompute (class in onmt.utils.loss)": [[15, "onmt.utils.loss.LossCompute"]], "nmtmodel (class in onmt.models)": [[15, "onmt.models.NMTModel"]], "optimizer (class in onmt.utils)": [[15, "onmt.utils.Optimizer"]], "statistics (class in onmt.utils)": [[15, "onmt.utils.Statistics"]], "trainer (class in onmt)": [[15, "onmt.Trainer"]], "accuracy() (onmt.utils.statistics method)": [[15, "onmt.utils.Statistics.accuracy"]], "all_gather_stats() (onmt.utils.statistics static method)": [[15, "onmt.utils.Statistics.all_gather_stats"]], "all_gather_stats_list() (onmt.utils.statistics static method)": [[15, "onmt.utils.Statistics.all_gather_stats_list"]], "amp (onmt.utils.optimizer property)": [[15, "onmt.utils.Optimizer.amp"]], "backward() (onmt.utils.optimizer method)": [[15, "onmt.utils.Optimizer.backward"]], "count_parameters() (onmt.models.languagemodel method)": [[15, "onmt.models.LanguageModel.count_parameters"]], "count_parameters() (onmt.models.nmtmodel method)": [[15, "onmt.models.NMTModel.count_parameters"]], "elapsed_time() (onmt.utils.statistics method)": [[15, "onmt.utils.Statistics.elapsed_time"]], "forward() (onmt.models.basemodel method)": [[15, "onmt.models.BaseModel.forward"]], "forward() (onmt.models.languagemodel method)": [[15, "onmt.models.LanguageModel.forward"]], "forward() (onmt.models.nmtmodel method)": [[15, "onmt.models.NMTModel.forward"]], "forward() (onmt.utils.loss.losscompute method)": [[15, "onmt.utils.loss.LossCompute.forward"]], "from_opt() (onmt.utils.optimizer class method)": [[15, "onmt.utils.Optimizer.from_opt"]], "from_opts() (onmt.utils.loss.losscompute class method)": [[15, "onmt.utils.loss.LossCompute.from_opts"]], "learning_rate() (onmt.utils.optimizer method)": [[15, "onmt.utils.Optimizer.learning_rate"]], "log_tensorboard() (onmt.utils.statistics method)": [[15, "onmt.utils.Statistics.log_tensorboard"]], "output() (onmt.utils.statistics method)": [[15, "onmt.utils.Statistics.output"]], "ppl() (onmt.utils.statistics method)": [[15, "onmt.utils.Statistics.ppl"]], "step() (onmt.utils.adafactor method)": [[15, "onmt.utils.AdaFactor.step"]], "step() (onmt.utils.fusedadam method)": [[15, "onmt.utils.FusedAdam.step"]], "step() (onmt.utils.optimizer method)": [[15, "onmt.utils.Optimizer.step"]], "train() (onmt.trainer method)": [[15, "onmt.Trainer.train"]], "training_step (onmt.utils.optimizer property)": [[15, "onmt.utils.Optimizer.training_step"]], "update() (onmt.utils.statistics method)": [[15, "onmt.utils.Statistics.update"]], "validate() (onmt.trainer method)": [[15, "onmt.Trainer.validate"]], "xent() (onmt.utils.statistics method)": [[15, "onmt.utils.Statistics.xent"]], "zero_grad() (onmt.utils.optimizer method)": [[15, "onmt.utils.Optimizer.zero_grad"]], "dynamicdatasetiter (class in onmt.inputters)": [[16, "onmt.inputters.DynamicDatasetIter"]], "mixingstrategy (class in onmt.inputters)": [[16, "onmt.inputters.MixingStrategy"]], "parallelcorpus (class in onmt.inputters)": [[16, "onmt.inputters.ParallelCorpus"]], "parallelcorpusiterator (class in onmt.inputters)": [[16, "onmt.inputters.ParallelCorpusIterator"]], "sequentialmixer (class in onmt.inputters)": [[16, "onmt.inputters.SequentialMixer"]], "weightedmixer (class in onmt.inputters)": [[16, "onmt.inputters.WeightedMixer"]], "batch_iter() (onmt.inputters.dynamicdatasetiter method)": [[16, "onmt.inputters.DynamicDatasetIter.batch_iter"]], "from_opt() (onmt.inputters.dynamicdatasetiter class method)": [[16, "onmt.inputters.DynamicDatasetIter.from_opt"]], "load() (onmt.inputters.parallelcorpus method)": [[16, "onmt.inputters.ParallelCorpus.load"]], "averageattention (class in onmt.modules)": [[17, "onmt.modules.AverageAttention"]], "cnndecoder (class in onmt.decoders)": [[17, "onmt.decoders.CNNDecoder"]], "cnnencoder (class in onmt.encoders)": [[17, "onmt.encoders.CNNEncoder"]], "convmultistepattention (class in onmt.modules)": [[17, "onmt.modules.ConvMultiStepAttention"]], "copygenerator (class in onmt.modules)": [[17, "onmt.modules.CopyGenerator"]], "decoderbase (class in onmt.decoders)": [[17, "onmt.decoders.DecoderBase"]], "embeddings (class in onmt.modules)": [[17, "onmt.modules.Embeddings"]], "encoderbase (class in onmt.encoders)": [[17, "onmt.encoders.EncoderBase"]], "ggnnencoder (class in onmt.encoders)": [[17, "onmt.encoders.GGNNEncoder"]], "globalattention (class in onmt.modules)": [[17, "onmt.modules.GlobalAttention"]], "inputfeedrnndecoder (class in onmt.decoders)": [[17, "onmt.decoders.InputFeedRNNDecoder"]], "matrixtree (class in onmt.modules.structured_attention)": [[17, "onmt.modules.structured_attention.MatrixTree"]], "meanencoder (class in onmt.encoders)": [[17, "onmt.encoders.MeanEncoder"]], "multiheadedattention (class in onmt.modules)": [[17, "onmt.modules.MultiHeadedAttention"]], "positionalencoding (class in onmt.modules)": [[17, "onmt.modules.PositionalEncoding"]], "positionwisefeedforward (class in onmt.modules.position_ffn)": [[17, "onmt.modules.position_ffn.PositionwiseFeedForward"]], "rnndecoderbase (class in onmt.decoders.decoder)": [[17, "onmt.decoders.decoder.RNNDecoderBase"]], "rnnencoder (class in onmt.encoders)": [[17, "onmt.encoders.RNNEncoder"]], "stdrnndecoder (class in onmt.decoders)": [[17, "onmt.decoders.StdRNNDecoder"]], "transformerdecoder (class in onmt.decoders)": [[17, "onmt.decoders.TransformerDecoder"]], "transformerencoder (class in onmt.encoders)": [[17, "onmt.encoders.TransformerEncoder"]], "apply_mask() (onmt.modules.convmultistepattention method)": [[17, "onmt.modules.ConvMultiStepAttention.apply_mask"]], "emb_luts (onmt.modules.embeddings property)": [[17, "onmt.modules.Embeddings.emb_luts"]], "forward() (onmt.decoders.cnndecoder method)": [[17, "onmt.decoders.CNNDecoder.forward"]], "forward() (onmt.decoders.transformerdecoder method)": [[17, "onmt.decoders.TransformerDecoder.forward"]], "forward() (onmt.decoders.decoder.rnndecoderbase method)": [[17, "onmt.decoders.decoder.RNNDecoderBase.forward"]], "forward() (onmt.encoders.cnnencoder method)": [[17, "onmt.encoders.CNNEncoder.forward"]], "forward() (onmt.encoders.encoderbase method)": [[17, "onmt.encoders.EncoderBase.forward"]], "forward() (onmt.encoders.ggnnencoder method)": [[17, "onmt.encoders.GGNNEncoder.forward"]], "forward() (onmt.encoders.meanencoder method)": [[17, "onmt.encoders.MeanEncoder.forward"]], "forward() (onmt.encoders.rnnencoder method)": [[17, "onmt.encoders.RNNEncoder.forward"]], "forward() (onmt.encoders.transformerencoder method)": [[17, "onmt.encoders.TransformerEncoder.forward"]], "forward() (onmt.modules.averageattention method)": [[17, "onmt.modules.AverageAttention.forward"]], "forward() (onmt.modules.convmultistepattention method)": [[17, "onmt.modules.ConvMultiStepAttention.forward"]], "forward() (onmt.modules.copygenerator method)": [[17, "onmt.modules.CopyGenerator.forward"]], "forward() (onmt.modules.embeddings method)": [[17, "onmt.modules.Embeddings.forward"]], "forward() (onmt.modules.globalattention method)": [[17, "onmt.modules.GlobalAttention.forward"]], "forward() (onmt.modules.multiheadedattention method)": [[17, "onmt.modules.MultiHeadedAttention.forward"]], "forward() (onmt.modules.positionalencoding method)": [[17, "onmt.modules.PositionalEncoding.forward"]], "forward() (onmt.modules.position_ffn.positionwisefeedforward method)": [[17, "onmt.modules.position_ffn.PositionwiseFeedForward.forward"]], "forward() (onmt.modules.structured_attention.matrixtree method)": [[17, "onmt.modules.structured_attention.MatrixTree.forward"]], "from_opt() (onmt.decoders.cnndecoder class method)": [[17, "onmt.decoders.CNNDecoder.from_opt"]], "from_opt() (onmt.decoders.decoderbase class method)": [[17, "onmt.decoders.DecoderBase.from_opt"]], "from_opt() (onmt.decoders.decoder.rnndecoderbase class method)": [[17, "onmt.decoders.decoder.RNNDecoderBase.from_opt"]], "from_opt() (onmt.encoders.cnnencoder class method)": [[17, "onmt.encoders.CNNEncoder.from_opt"]], "from_opt() (onmt.encoders.ggnnencoder class method)": [[17, "onmt.encoders.GGNNEncoder.from_opt"]], "from_opt() (onmt.encoders.meanencoder class method)": [[17, "onmt.encoders.MeanEncoder.from_opt"]], "from_opt() (onmt.encoders.rnnencoder class method)": [[17, "onmt.encoders.RNNEncoder.from_opt"]], "from_opt() (onmt.encoders.transformerencoder class method)": [[17, "onmt.encoders.TransformerEncoder.from_opt"]], "init_state() (onmt.decoders.cnndecoder method)": [[17, "onmt.decoders.CNNDecoder.init_state"]], "init_state() (onmt.decoders.decoder.rnndecoderbase method)": [[17, "onmt.decoders.decoder.RNNDecoderBase.init_state"]], "load_pretrained_vectors() (onmt.modules.embeddings method)": [[17, "onmt.modules.Embeddings.load_pretrained_vectors"]], "score() (onmt.modules.globalattention method)": [[17, "onmt.modules.GlobalAttention.score"]], "word_lut (onmt.modules.embeddings property)": [[17, "onmt.modules.Embeddings.word_lut"]], "servermodel (class in onmt.translate.translation_server)": [[18, "onmt.translate.translation_server.ServerModel"]], "servermodelerror": [[18, "onmt.translate.translation_server.ServerModelError"]], "timer (class in onmt.translate.translation_server)": [[18, "onmt.translate.translation_server.Timer"]], "translationserver (class in onmt.translate.translation_server)": [[18, "onmt.translate.translation_server.TranslationServer"]], "build_tokenizer() (onmt.translate.translation_server.servermodel method)": [[18, "onmt.translate.translation_server.ServerModel.build_tokenizer"]], "clone_model() (onmt.translate.translation_server.translationserver method)": [[18, "onmt.translate.translation_server.TranslationServer.clone_model"]], "detokenize() (onmt.translate.translation_server.servermodel method)": [[18, "onmt.translate.translation_server.ServerModel.detokenize"]], "do_timeout() (onmt.translate.translation_server.servermodel method)": [[18, "onmt.translate.translation_server.ServerModel.do_timeout"]], "list_models() (onmt.translate.translation_server.translationserver method)": [[18, "onmt.translate.translation_server.TranslationServer.list_models"]], "load_model() (onmt.translate.translation_server.translationserver method)": [[18, "onmt.translate.translation_server.TranslationServer.load_model"]], "maybe_convert_align() (onmt.translate.translation_server.servermodel method)": [[18, "onmt.translate.translation_server.ServerModel.maybe_convert_align"]], "maybe_detokenize() (onmt.translate.translation_server.servermodel method)": [[18, "onmt.translate.translation_server.ServerModel.maybe_detokenize"]], "maybe_detokenize_with_align() (onmt.translate.translation_server.servermodel method)": [[18, "onmt.translate.translation_server.ServerModel.maybe_detokenize_with_align"]], "maybe_postprocess() (onmt.translate.translation_server.servermodel method)": [[18, "onmt.translate.translation_server.ServerModel.maybe_postprocess"]], "maybe_preprocess() (onmt.translate.translation_server.servermodel method)": [[18, "onmt.translate.translation_server.ServerModel.maybe_preprocess"]], "maybe_tokenize() (onmt.translate.translation_server.servermodel method)": [[18, "onmt.translate.translation_server.ServerModel.maybe_tokenize"]], "maybe_transform_feats() (onmt.translate.translation_server.servermodel method)": [[18, "onmt.translate.translation_server.ServerModel.maybe_transform_feats"]], "parse_opt() (onmt.translate.translation_server.servermodel method)": [[18, "onmt.translate.translation_server.ServerModel.parse_opt"]], "postprocess() (onmt.translate.translation_server.servermodel method)": [[18, "onmt.translate.translation_server.ServerModel.postprocess"]], "preload_model() (onmt.translate.translation_server.translationserver method)": [[18, "onmt.translate.translation_server.TranslationServer.preload_model"]], "preprocess() (onmt.translate.translation_server.servermodel method)": [[18, "onmt.translate.translation_server.ServerModel.preprocess"]], "rebuild_seg_packages() (onmt.translate.translation_server.servermodel method)": [[18, "onmt.translate.translation_server.ServerModel.rebuild_seg_packages"]], "run() (onmt.translate.translation_server.translationserver method)": [[18, "onmt.translate.translation_server.TranslationServer.run"]], "start() (onmt.translate.translation_server.translationserver method)": [[18, "onmt.translate.translation_server.TranslationServer.start"]], "to_gpu() (onmt.translate.translation_server.servermodel method)": [[18, "onmt.translate.translation_server.ServerModel.to_gpu"]], "tokenize() (onmt.translate.translation_server.servermodel method)": [[18, "onmt.translate.translation_server.ServerModel.tokenize"]], "tokenizer_marker() (onmt.translate.translation_server.servermodel method)": [[18, "onmt.translate.translation_server.ServerModel.tokenizer_marker"]], "unload_model() (onmt.translate.translation_server.translationserver method)": [[18, "onmt.translate.translation_server.TranslationServer.unload_model"]], "beamsearch (class in onmt.translate)": [[19, "onmt.translate.BeamSearch"]], "decodestrategy (class in onmt.translate)": [[19, "onmt.translate.DecodeStrategy"]], "gnmtglobalscorer (class in onmt.translate)": [[19, "onmt.translate.GNMTGlobalScorer"]], "greedysearch (class in onmt.translate)": [[19, "onmt.translate.GreedySearch"]], "penaltybuilder (class in onmt.translate.penalties)": [[19, "onmt.translate.penalties.PenaltyBuilder"]], "translation (class in onmt.translate)": [[19, "onmt.translate.Translation"]], "translationbuilder (class in onmt.translate)": [[19, "onmt.translate.TranslationBuilder"]], "translator (class in onmt.translate)": [[19, "onmt.translate.Translator"]], "advance() (onmt.translate.decodestrategy method)": [[19, "onmt.translate.DecodeStrategy.advance"]], "advance() (onmt.translate.greedysearch method)": [[19, "onmt.translate.GreedySearch.advance"]], "block_ngram_repeats() (onmt.translate.decodestrategy method)": [[19, "onmt.translate.DecodeStrategy.block_ngram_repeats"]], "coverage_none() (onmt.translate.penalties.penaltybuilder method)": [[19, "onmt.translate.penalties.PenaltyBuilder.coverage_none"]], "coverage_summary() (onmt.translate.penalties.penaltybuilder method)": [[19, "onmt.translate.penalties.PenaltyBuilder.coverage_summary"]], "coverage_wu() (onmt.translate.penalties.penaltybuilder method)": [[19, "onmt.translate.penalties.PenaltyBuilder.coverage_wu"]], "initialize() (onmt.translate.beamsearch method)": [[19, "onmt.translate.BeamSearch.initialize"]], "initialize() (onmt.translate.decodestrategy method)": [[19, "onmt.translate.DecodeStrategy.initialize"]], "initialize() (onmt.translate.greedysearch method)": [[19, "onmt.translate.GreedySearch.initialize"]], "length_average() (onmt.translate.penalties.penaltybuilder method)": [[19, "onmt.translate.penalties.PenaltyBuilder.length_average"]], "length_none() (onmt.translate.penalties.penaltybuilder method)": [[19, "onmt.translate.penalties.PenaltyBuilder.length_none"]], "length_wu() (onmt.translate.penalties.penaltybuilder method)": [[19, "onmt.translate.penalties.PenaltyBuilder.length_wu"]], "log() (onmt.translate.translation method)": [[19, "onmt.translate.Translation.log"]], "maybe_update_forbidden_tokens() (onmt.translate.decodestrategy method)": [[19, "onmt.translate.DecodeStrategy.maybe_update_forbidden_tokens"]], "maybe_update_target_prefix() (onmt.translate.decodestrategy method)": [[19, "onmt.translate.DecodeStrategy.maybe_update_target_prefix"]], "sample_with_temperature() (in module onmt.translate.greedy_search)": [[19, "onmt.translate.greedy_search.sample_with_temperature"]], "target_prefixing() (onmt.translate.decodestrategy method)": [[19, "onmt.translate.DecodeStrategy.target_prefixing"]], "translate_batch() (onmt.translate.translator method)": [[19, "onmt.translate.Translator.translate_batch"]], "update_finished() (onmt.translate.decodestrategy method)": [[19, "onmt.translate.DecodeStrategy.update_finished"]], "update_finished() (onmt.translate.greedysearch method)": [[19, "onmt.translate.GreedySearch.update_finished"]]}})